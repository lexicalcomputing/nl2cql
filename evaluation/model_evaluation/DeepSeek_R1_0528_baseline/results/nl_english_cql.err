'lemmas ending with -ment\tpreloaded/ententen21_tt31\t[lemma=".*ment"]\n'
On line 1
[lemma=".+ment$"]  // .+ = one or more characters
'tokens that are exactly semicolons\tpreloaded/ententen21_tt31\t[word==";"]\n'
On line 2
[word=";" & pos="PUNCT"]
'five-letter lowercase words\tpreloaded/ententen21_tt31\t[word="[[:lower:]]{5}"]\n'
On line 3
plaintext"apple", "house", "zebra"
'words starting with trans-\tpreloaded/ententen21_tt31\t[word="trans.*"]\n'
On line 4
[word="^trans.*"]
'words ending with -able or -ible\tpreloaded/ententen21_tt31\t[word=".*[ai]ble"]\n'
On line 5
[word="(?i).*[ai]ble$"]
'lemmas starting with micro- and ending with -scope\tpreloaded/ententen21_tt31\t[lemma="micro.*scope"]\n'
On line 6
[lemma="(?i)micro.*scope"]
'tokens that contain a hyphen\tpreloaded/ententen21_tt31\t[word=".*-.*"]\n'
On line 7
[word=".*[-—].*" & pos="ADJ"]
'tokens that are only digits\tpreloaded/ententen21_tt31\t[word="\\d+"]\n'
On line 8
[word="\\d+"]
'tokens that are punctuation\tpreloaded/ententen21_tt31\t[word="[[:punct:]]+"]\n'
On line 9
/* Penn Treebank fallback (check your corpus tags first): */[tag=.|tag=,|tag=:|tag=``|tag=''|tag=-LRB-|tag=-RRB-]
'any finite verb\tpreloaded/ententen21_tt31\t[tag="V[VBH][PZD]"]\n'
On line 10
[tag="VERB" & morph_contains="VerbForm=Fin"]
'any common noun\tpreloaded/ententen21_tt31\t[tag="NN|NNS"]\n'
On line 11
[pos="NN"] | [pos="NNS"]
'any proper noun token\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]\n'
On line 12
[pos="NNP|NNPS|PROPN|NP"]
'wh-determiners\tpreloaded/ententen21_tt31\t[tag="WDT"]\n'
On line 13
[pos="WDT"] .*? [pos="\?"]
'wh-adverbs\tpreloaded/ententen21_tt31\t[tag="WRB"]\n'
On line 14
[word="w(hy|hen|ere)" | word="how"]  // regex variant
'base adjectives\tpreloaded/ententen21_tt31\t[tag="JJ"]\n'
On line 15
perl   [word="(?i)interesting"] [pos="JJ"]  // Finds "Interesting case", "INTERESTING result", etc.
'base adverbs\tpreloaded/ententen21_tt31\t[tag="RB"]\n'
On line 16
[pos = "RB" & tag != "RB[ADV]" & tag != "R.*"]  // Excludes derived forms/comparatives
'coordinating conjunction "and"\tpreloaded/ententen21_tt31\t[lemma=="and" & tag="CC"]\n'
On line 17
[word="[aA]nd" & pos="CC"]
'determiners \'a|an|the\'\tpreloaded/ententen21_tt31\t[lemma="a|an|the" & tag="DT"]\n'
On line 18
[word="(?i)^(a|an|the)$"]
'comparatives ending by -er\tpreloaded/ententen21_tt31\t[word=".*er" & tag="JJR"]\n'
On line 19
[tag="JJR" & word=".*er$"]
'superlatives ending by -est\tpreloaded/ententen21_tt31\t[word=".*est" & tag="JJS"]\n'
On line 20
[word=".*(ie|ie?)?[sS][tT]" & pos="JJS"]  /* Matches -iest / -est */
'comparatives not ending by -er\tpreloaded/ententen21_tt31\t[word!=".*er" & tag="JJR"]\n'
On line 21
[tag="(JJR|RBR)" & !word=".*[eE][rR]$"]
'superlatives not ending by -est\tpreloaded/ententen21_tt31\t[word!=".*est" & tag="JJS"]\n'
On line 22
[pos="JJS|RBS" & word!="*est"]
'plural nouns ending with -ies\tpreloaded/ententen21_tt31\t[word=".*ies" & tag="NNS"]\n'
On line 23
[word=".*[iI][eE][sS]$" & pos="NNS"]
'plural nouns ending with -s\tpreloaded/ententen21_tt31\t[word=".*s" & tag="NNS"]\n'
On line 24
[word=".*s$" & (tag="NNS" | tag="NNPS")]
'verbs ending with -ed (past forms)\tpreloaded/ententen21_tt31\t[word=".*ed" & tag="V[VBH][DN]"]\n'
On line 25
[word=".+ed" & (feats.VerbForm="Part" | feats.Tense="Past")]
'contractions ending n\'t\tpreloaded/ententen21_tt31\t</g>[word="n\'t"]\n'
On line 26
[word=".*n't"]  // Matches any token ending with "n't" (case-sensitive)
'tokens with an apostrophe\tpreloaded/ententen21_tt31\t[word=".*\'.*"]\n'
On line 27
[word=".*'.*"]
'currency symbols $ £ €\tpreloaded/ententen21_tt31\t[word="$|£|€"]\n'
On line 28
[word="$" | word="£" | word="€" | word="[$£€][0-9]+"]
'tokens like (c) or (R)\tpreloaded/ententen21_tt31\t[word=="("][word="(c|C|r|R)"][word==")"]\n'
On line 29
"(&copy;|&reg;|\([cCrR]\))"
'cardinal numbers with decimals\tpreloaded/ententen21_tt31\t[word="\\d+\\.\\d+" & tag="CD"]\n'
On line 30
[tag="CD" & word=".*(\\.|,).*"]   // Match either dot or comma
'numbers with percent sign\tpreloaded/ententen21_tt31\t[word="\\d+(\\.\\d+)?"][word="%"]\n'
On line 31
cpp  ( [pos="NUM"] [word~"%|％"] )
'time like 7:30 pm\tpreloaded/ententen21_tt31\t[word="[1-2]?\\d:[0-5]\\d"][word="am|pm|AM|PM"]\n'
On line 32
(  [word="[0-9]{1,2}"] [word=":"] [word="[0-9]{2}"] [word="[ap]\.?[m]\.?" case_insensitive=true]  |  [word="[0-9]{1,2}:[0-9]{2}"] [word="[ap]\.?[m]\.?" case_insensitive=true]  |  [word="[0-9]{1,2}:[0-9]{2}\s*[ap]\.?[m]\.?" case_insensitive=true])
'sentence starts with a quote\tpreloaded/ententen21_tt31\t<s> [word="\\"|“|‘|\'"]\n'
On line 33
// If using positional constraints (e.g., ANNIS)   :: start [word="\""]      // For Sketch Engine   [] :: match.sentenceCount=1 & word="\""
'sentence ends with an exclamation mark\tpreloaded/ententen21_tt31\t[word=="!"] </s>\n'
On line 34
[word="!"] | [word="!"] [word="\""] :z(end, s)
'tokens that are open parenthesis\tpreloaded/ententen21_tt31\t[word=="("]\n'
On line 35
[word="\("]
'tokens that are close parenthesis\tpreloaded/ententen21_tt31\t[word==")"]\n'
On line 36
[word=")" | word="]" | word="}"]
'bracketed content up to 7 tokens\tpreloaded/ententen21_tt31\t[word=="("][]{0,7}[word==")"]\n'
On line 37
"[" []{1,5} "]"
'quoted spans up to 6 tokens\tpreloaded/ententen21_tt31\t[word="\\""][]{0,6}[word="\\""]\n'
On line 38
(    [word="\""]    ([word!="\""]{0,4})  // Only tokens WITHOUT straight quotes inside    [word="\""]  ) | (    [word="“"]    ([word!="“" & word!="”"]{0,4})  // Exclude curly quotes inside    [word="”"]  )
'‘Mr.’ or ‘Ms.’ before a name\tpreloaded/ententen21_tt31\t[word="Mr\\.|Ms\\.|Mrs\\.|Dr\\."][tag="NP"]\n'
On line 39
[word="Mr.?|Ms.?"] [pos="PROPN"]
'personal pronoun followed by be\tpreloaded/ententen21_tt31\t[tag="PP"][lemma="be"]\n'
On line 40
[pos="PRP"] [lemma="be"]
'proper noun followed by be\tpreloaded/ententen21_tt31\t[tag="NP"][lemma="be"]\n'
On line 41
[pos="PROPN"] [lemma="be" & pos="AUX"]
'noun preceded by exactly one adjective\tpreloaded/ententen21_tt31\t[tag="J.*"][tag="N.*"]\n'
On line 42
((<s/>) | [tag != "ADJ"]) [tag="ADJ"] [tag="ADV"]? [][0,1] [tag="NOUN"]  // Example for 0-1 adverbs
'noun preceded by two adjectives\tpreloaded/ententen21_tt31\t[tag="J.*"]{2}[tag="N.*"]\n'
On line 43
[tag = "JJ.*"] [tag = "JJ.*"] [tag = "NN.*"]
'noun preceded by 0–3 adjectives\tpreloaded/ententen21_tt31\t[tag="J.*"]{0,3}[tag="N.*"]\n'
On line 44
([pos="ADJ"] | []){3} [pos="NOUN"]
'adverb immediately before an adjective\tpreloaded/ententen21_tt31\t[tag="RB.*"][tag="J.*"]\n'
On line 45
[pos="RB|RBR|RBS"] [pos="JJ|JJR|JJS"]
'adjective immediately before a verb\tpreloaded/ententen21_tt31\t[tag="J.*"][tag="V.*"]\n'
On line 46
[tag="JJ.*"] [tag="VB.*"]
'verb immediately before a noun\tpreloaded/ententen21_tt31\t[tag="V.*"][tag="N.*"]\n'
On line 47
[pos="V.*"] [pos="N.*"]
'determiner + adjective + noun\tpreloaded/ententen21_tt31\t[tag="DT"][tag="J.*"][tag="N.*"]\n'
On line 48
[pos="DET"] [pos="ADJ"] [pos="NOUN"]
'proper-noun bigrams\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]{2}\n'
On line 49
[pos="NNP|NNPS"] [pos="NNP|NNPS"]
'three-token proper-noun sequences\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]{3}\n'
On line 50
[tag="PROPN"] [tag="PROPN"] [tag="PROPN"]
'noun-noun compounds of length 3\tpreloaded/ententen21_tt31\t[tag="N.*"]{3}\n'
On line 51
[lemma="word1" & pos="NOUN"] [lemma="word2" & pos="NOUN"] [lemma="word3" & pos="NOUN"]
'verb + particle (RP) with <3 gap\tpreloaded/ententen21_tt31\t[tag="V.*"][]{0,2}[tag="RP"]\n'
On line 52
[pos="V.*"] [pos!="V.*"]{0,2} [pos="RP"]  // Exclude intervening verbs
'verb + adverb + particle\tpreloaded/ententen21_tt31\t[tag="V.*"][tag="RB.*"][tag="RP"]\n'
On line 53
[pos="VB"] [pos="RB"] [pos="RP"]
'be + not + adjective\tpreloaded/ententen21_tt31\t[lemma="be"][lemma="not"][tag="J.*"]\n'
On line 54
[lemma="be"] [word="not" | word="n't"] [pos="ADJ"]
'do-support negation + base verb\tpreloaded/ententen21_tt31\t[lemma="do"][lemma="not"][tag="V[BHV]"]\n'
On line 55
[lemma="do" & (tag="VBD"|tag="VBP"|tag="VBZ")] [word="not"|word="n't"] [tag="VB" & lemma!="except|have|be"]  // Excludes auxiliary verbs in base form
'want to + base verb\tpreloaded/ententen21_tt31\t[lemma="want"][lemma="to"][tag="V[BHV]"]\n'
On line 56
[lemma="want"] [word="to"] []{0,3} [tag="VB"]
'need to + base verb\tpreloaded/ententen21_tt31\t[lemma="need"][lemma="to"][tag="V[BHV]"]\n'
On line 57
[lemma="need"] [word="to" & pos="TO"] []{0,2} [pos="VB"]
'plan to + base verb\tpreloaded/ententen21_tt31\t[lemma="plan"][lemma="to"][tag="V[BHV]"]\n'
On line 58
[lemma="plan" & pos="V.*"] "to" ([pos="RB"] | []){0,2} [pos="VB"]
'try to + base verb\tpreloaded/ententen21_tt31\t[lemma="try"][lemma="to"][tag="V[BHV]"]\n'
On line 59
[lemma="try"] "to" [lemma="go" & pos="VB"]
'be going to + base verb\tpreloaded/ententen21_tt31\t[lemma="be"][lemma="going"][lemma="to"][tag="V[BHV]"]\n'
On line 60
python# CQL for: be going to + base verb[lemma="be"] []{0,3} [lemma="go" & tag="VBG"] [tag="TO"] []{0,5} [tag="VB"][!tag="VBG"]*
'have to + base verb\tpreloaded/ententen21_tt31\t[lemma="have"][lemma="to"][tag="V[BHV]"]\n'
On line 61
sql   // Reject sentence-final matches   ([lemma="have"] [word="to" & tag="TO"] [tag="VB"]) :[endswith != "VB"]
'used to + base verb\tpreloaded/ententen21_tt31\t[lemma="use"][lemma="to"][tag="V[BHV]"]\n'
On line 62
/* 1. Strict version (immediately adjacent) */[word="used"][word="to"][pos="VB"]/* 2. Flexible version (allows adverbs like 'always', 'never') */[word="used"][word="to"] ([pos="RB" | word="never|always|sometimes"])? [pos="VB"]
'would rather + base verb\tpreloaded/ententen21_tt31\t[word=="would"][word=="rather"][tag="V[BHV]"]\n'
On line 63
[lemma="would" | word="'d"]  [word="rather"]  [tag="VB"]
'had better + base verb\tpreloaded/ententen21_tt31\t[word=="had"][word=="better"][tag="V[BHV]"]\n'
On line 64
[word="had"][word="better"]([tag="RB" & lemma!=".?"]){0,3}[tag="VB"]
'prefer to + base verb\tpreloaded/ententen21_tt31\t[lemma="prefer"][lemma="to"][tag="V[BHV]"]\n'
On line 65
[lemma="prefer"] [word="to"] [tag="R.*"]{0,1} [pos="VB"]
'ask NOUN to + base verb\tpreloaded/ententen21_tt31\t[lemma="ask"][tag="N.*"][lemma="to"][tag="V[BHV]"]\n'
On line 66
[lemma="ask"] []{0,2} [pos="NOUN"] []{0,2} "to" []{0,2} [pos="VB"]
'tell NOUN to + base verb\tpreloaded/ententen21_tt31\t[lemma="tell"][tag="N.*"][lemma="to"][tag="V[BHV]"]\n'
On line 67
[lemma="tell"] [tag="N.*"] "to"[tag="TO"] []{0,3} [tag="VB"]  (*Searches up to 3 tokens between "to" and base verb*)
'allow PRON to + base verb\tpreloaded/ententen21_tt31\t[lemma="allow"][tag="PP|WP|WPZ"][lemma="to"][tag="V[BHV]"]\n'
On line 68
[upos="PRON"] []{0,3} [word="to"] []{0,3} [upos="VERB" & VerbForm=Inf]
'promise to + base verb\tpreloaded/ententen21_tt31\t[lemma="promise"][lemma="to"][tag="V[BHV]"]\n'
On line 69
[lemma="promise"] [upos="PART" & word="to"] [upos="VERB" & feats.*="VerbForm=Inf"]
'begin to + base verb\tpreloaded/ententen21_tt31\t[lemma="begin"][lemma="to"][tag="V[BHV]"]\n'
On line 70
[lemma="begin"] [word="to" & pos="TO"] [pos~"V..?|VB"]
'continue to + base verb\tpreloaded/ententen21_tt31\t[lemma="continue"][lemma="to"][tag="V[BHV]"]\n'
On line 71
[lemma="continue"] [word="to" & pos="TO"] [pos="VB"]
'seem to + base verb\tpreloaded/ententen21_tt31\t[lemma="seem"][lemma="to"][tag="V[BHV]"]\n'
On line 72
[lemma="seem"] "to" [pos="RB|RP"]{0,2} [pos="VB"]
'happen to + base verb\tpreloaded/ententen21_tt31\t[lemma="happen"][lemma="to"][tag="V[BHV]"]\n'
On line 73
[lemma="happen"] [lemma="to" & pos="TO"] []{0,2} [pos="VB"]
'appear to + base verb\tpreloaded/ententen21_tt31\t[lemma="appear"][lemma="to"][tag="V[BHV]"]\n'
On line 74
[lemma="appear"] [pos="TO"] [pos="VB"]
'be about to + base verb\tpreloaded/ententen21_tt31\t[lemma="be"][lemma="about"][lemma="to"][tag="V[BHV]"]\n'
On line 75
[lemma="be"] "about" "to" [][pos=RB]{0,3} [][pos="VB"]
'try not to + base verb\tpreloaded/ententen21_tt31\t[lemma="try"][lemma="not"][lemma="to"][tag="V[BHV]"]\n'
On line 76
[lemma="try"][pos="V.*"] ("not"|"n't") "to" [pos="VB"]
'adjective with not\tpreloaded/ententen21_tt31\t[lemma="not"][tag="J.*"]\n'
On line 77
[word="not" | word="n't"] []{0,1} [pos="ADJ"]
'noun with no\tpreloaded/ententen21_tt31\t[lemma="no"][tag="N.*"]\n'
On line 78
[word="no" & pos="DET"] [pos="NOUN"]
'no + adjective + noun\tpreloaded/ententen21_tt31\t[lemma="no"][tag="J.*"]?[tag="N.*"]\n'
On line 79
"no" [][pos="RB.*"]? [pos="JJ.*"] [pos="NN.*"]
'not + verb within one token\tpreloaded/ententen21_tt31\t(meet [tag="V.*"] [lemma="not"] -1 1)\n'
On line 80
[lemma="not"][pos^="VB" & pos!="RB"]
'verb within three tokens of risk\tpreloaded/ententen21_tt31\t(meet [tag="V.*"] [lemma="risk"] -3 3)\n'
On line 81
(  [word="risk" & pos="V.*"]    -- Verb AT "risk"   |   [pos="V.*"] []{,2} [word="risk"]   -- Verb BEFORE "risk" (0–2 tokens between)  |  [word="risk"] []{,2} [pos="V.*"]   -- Verb AFTER "risk" (0–2 tokens between))
'adjectives within two tokens of seem\tpreloaded/ententen21_tt31\t(meet [tag="J.*"] [lemma="seem"] -2 2)\n'
On line 82
([pos="ADJ"] []{0,2} [lemma="seem]) | ([lemma="seem"] []{0,2} [pos="ADJ"])
'noun within five tokens of increase\tpreloaded/ententen21_tt31\t(meet [tag="N.*"] [lemma="increase"] -5 5)\n'
On line 83
> ([pos="NOUN"] .{0,5} [word="increase"]) | ([word="increase"] .{0,5} [pos="NOUN"])>
'union of verbs/adjectives near be\tpreloaded/ententen21_tt31\t(union (meet [tag="V.*"] [lemma="be"] -3 3) (meet [tag="J.*"] [lemma="be"] -2 2))\n'
On line 84
(  [pos = "ADJ" | pos = "VERB"]  # Target: Adjective or Verb  [ ]{0,3}                      # 0-3 arbitrary tokens in between  [lemma = "be"]                 # Anchor: Any form of "be") | (  [lemma = "be"]                 # Anchor: Any form of "be"  [ ]{0,3}                      # 0-3 arbitrary tokens in between  [pos = "ADJ" | pos = "VERB"]   # Target: Adjective or Verb)
'"either" and "or" within 6 tokens\tpreloaded/ententen21_tt31\t[word="either"][]{0,6}[word="or"]\n'
On line 85
([word="(?i)either"] []{0,5} [word="(?i)or"]) | ([word="(?i)or"] []{0,5} [word="(?i)either"])
'"neither" and "nor" within 6 tokens\tpreloaded/ententen21_tt31\t[word="neither"][]{0,6}[word="nor"]\n'
On line 86
text   "He likes neither coffee NOR tea"      // Adjacent (gap=0)   "Neither the price nor the quality"    // 2 tokens between   "Trust NOR his promises; NEITHER should you" // Order-swapped, gap=4
'"not only" and "but also" within 8 tokens\tpreloaded/ententen21_tt31\t[word=="not"][word="only"][]{0,8}[word=="but"][word=="also"]\n'
On line 87
[word="not"%c] [word="only"%c] []{0,8} [word="but"%c] [word="also"%c]
'as ADJ as within same sentence\tpreloaded/ententen21_tt31\t[word="as"][tag="J.*"][word="as"] within <s/>\n'
On line 88
[lemma="as"i] [ ]* [pos="ADJ"]{0,5} [ ]* [lemma="as"i]
'like a|an NOUN similes\tpreloaded/ententen21_tt31\t[lemma="like"][lemma="a|an"][tag="N.*"][word="similes"]\n'
On line 89
[word="like"|word="Like"] [word="a"|word="an"] [pos="N.*"]
'such a|an NOUN\tpreloaded/ententen21_tt31\t[word="such"][word="a|an"][tag="N.*"]\n'
On line 90
[word="such"] [word="a"|word="an"] ([pos="ADJ"]? [pos="NOUN"])
'so ADJ that within 3 tokens\tpreloaded/ententen21_tt31\t[lemma="so"][tag="J.*"][]{0,3}[word="that"]\n'
On line 91
[word="so"] [pos="ADJ"] [word="that"]
'too ADJ to VB\tpreloaded/ententen21_tt31\t[word="too"][tag="J.*"][word=="to"][tag="V[BHV]"]\n'
On line 92
[word="[tT]oo"] [tag="JJ|JJR|JJS"] [word="[tT]o"] [tag="VB"]
'enough NOUN\tpreloaded/ententen21_tt31\t[word="enough"][tag="N.*"]\n'
On line 93
[word="enough"] []{0,2} [pos="NOUN"]    // 0-2 words between
'very ADJ patterns\tpreloaded/ententen21_tt31\t[word="very"][tag="J.*"]\n'
On line 94
"very" [][pos="ADJ"]
'more/most ADJ\tpreloaded/ententen21_tt31\t[word="more|most"][tag="J.*"]\n'
On line 95
([word="more" & (pos="RBR"|pos="RB")] | [word="most" & (pos="RBS"|pos="RB")]) [pos="JJ.*"]
'more NOUN than NOUN\tpreloaded/ententen21_tt31\t[word="more"][tag="N.*"][word="than"][tag="N.*"]\n'
On line 96
"more" []{0,3} [pos="NOUN"] "than" []{0,3} [pos="NOUN"]
'the most ADJ\tpreloaded/ententen21_tt31\t[word="the"][word="most"][tag="J.*"]\n'
On line 97
[word="the" & pos="DET"] [word="most" & pos="ADV"] [pos="ADJ"]
'the least ADJ\tpreloaded/ententen21_tt31\t[word="the"][word="least"][tag="J.*"]\n'
On line 98
[lc="the"] [lc="least"] [tag="ADJ"]
'as soon as\tpreloaded/ententen21_tt31\t[word="as"][word="soon"][word="as"]\n'
On line 99
[word="[Aa][Ss]"] [word="[Ss][Oo][Oo][Nn]"] [word="[Aa][Ss]"]
'kind of NOUN\tpreloaded/ententen21_tt31\t[word=="kind"][word=="of"][tag="N.*"]\n'
On line 100
[lemma="kind"] [lemma="of"] []{0,2} [pos="NN.*"]
'sort of NOUN\tpreloaded/ententen21_tt31\t[word=="sort"][word=="of"][tag="N.*"]\n'
On line 101
[lemma="sort"] "of" []{0,2} [pos="NOUN"]  // Allows 0-2 words between phrase and noun
'according to NOUN/PRON\tpreloaded/ententen21_tt31\t[lemma="according"][lemma="to"][tag="N.*|PP|WP|WPZ"]\n'
On line 102
[word="according"] []{0,2} [word="to"] [pos="NOUN|PRON"]
'due to NOUN\tpreloaded/ententen21_tt31\t[lemma="due"][lemma="to"][tag="N.*"]\n'
On line 103
[word="[dD]ue"] [word="[tT]o"] [pos]
'because of NOUN\tpreloaded/ententen21_tt31\t[lemma="because"][lemma="of"][tag="N.*"]\n'
On line 104
[lemma="because"] [lemma="of"] ([pos="DET"] | [pos="ADJ"])* [pos="NOUN"]
'from NOUN to NOUN\tpreloaded/ententen21_tt31\t[word=="from"][tag="N.*"][word=="to"][tag="N.*"]\n'
On line 105
[pos="NOUN"] []* [pos="NOUN"] %c   // Within one corpus structure (e.g., sentence)
'between NOUN and NOUN\tpreloaded/ententen21_tt31\t[word=="between"][tag="N.*"][word=="and"][tag="N.*"]\n'
On line 106
[word="(?i)between"] [pos="NOUN"] [word="(?i)and"] [pos="NOUN.*"]
'NOUN such as NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][word=="such"][word=="as"][tag="N.*"]\n'
On line 107
[pos="NOUN"] ( [word=","] )? [word="(?i)such"] [word="(?i)as"] [pos="NOUN"]
'NOUN including NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="include"][tag="N.*"]\n'
On line 108
[pos="NOUN"] . [word="(?i)including"] [pos="NOUN"]  // . = any token gap
'NOUN especially NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="especially"][tag="N.*"]\n'
On line 109
( "especially" | "Especially" )
'NOUN like NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="like"][tag="N.*"]\n'
On line 110
[tag="NN.*"] ([-]? [tag="NN.*"])+
'NOUN named NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="name"][tag="N.*"]\n'
On line 111
[pos="NOUN"] "named" [pos="NOUN"]
'NOUN called NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="call"][tag="N.*"]\n'
On line 112
[pos="NOUN"] "called" [][pos="NOUN"]
'number of NOUN\tpreloaded/ententen21_tt31\t[lemma="number"][lemma="of"][tag="N.*"]\n'
On line 113
[pos="NOUN"]
'amount of NOUN\tpreloaded/ententen21_tt31\t[lemma="amount"][lemma="of"][tag="N.*"]\n'
On line 114
[word="amount"] [word="of"] [tag="NN|NNS|NNP|NNPS"]  // Singular/plural/proper nouns
'pair of NOUNS\tpreloaded/ententen21_tt31\t[lemma="pair"][lemma="of"][tag="N.*"]\n'
On line 115
[pos="NOUN"] [pos="NOUN"] %c
'group of NOUNS\tpreloaded/ententen21_tt31\t[lemma="group"][lemma="of"][tag="N.*"]\n'
On line 116
[tag="N.*"]{2,}     /* Regex: matches any noun tag starting with 'N' */
'lack of NOUN\tpreloaded/ententen21_tt31\t[lemma="lack"][lemma="of"][tag="N.*"]\n'
On line 117
[word="lack" & pos="NOUN"] "of" [pos="NOUN"]
'while ANY TOKEN\tpreloaded/ententen21_tt31\t[lemma="while"][]\n'
On line 118
"while" .*
'if <token>\tpreloaded/ententen21_tt31\t[lemma="if"][]\n'
On line 119
"if" []{0,3} "then"       # Match "if" with 0-3 tokens before "then"
'unless [token]\tpreloaded/ententen21_tt31\t[lemma="unless"][]\n'
On line 120
[word="unless"] [word=".*"]  # Regex wildcard for "any text"
'since []\tpreloaded/ententen21_tt31\t[lemma="since"][]\n'
On line 121
"since" []{0,5}  // Matches "since" + up to 5 arbitrary words
'during NOUN\tpreloaded/ententen21_tt31\t[lemma="during"][tag="N.*"]\n'
On line 122
[word="during"][]{0,2}[pos="NOUN" | pos="PROPN"]
'within NOUN\tpreloaded/ententen21_tt31\t[lemma="within"][tag="N.*"]\n'
On line 123
[word="within"] [pos="NN.*"]
'outside NOUN\tpreloaded/ententen21_tt31\t[lemma="outside"][tag="N.*"]\n'
On line 124
[word="outside" | word="Outside" | word="OUTSIDE"] [pos="NOUN"]
'into NOUN\tpreloaded/ententen21_tt31\t[lemma="into"][tag="N.*"]\n'
On line 125
[word="into" & (pos="NN" | pos="NNS" | pos="NNP" | pos="NNPS")]
'out of NOUN\tpreloaded/ententen21_tt31\t[lemma="out"][lemma="of"][tag="N.*"]\n'
On line 126
"out" "of" [pos = "NN|NNS|NNP"]
'onto NOUN\tpreloaded/ententen21_tt31\t[lemma="onto"][tag="N.*"]\n'
On line 127
python   "The function is an onto."  # Hypothetical mathematical context (tagged: onto/NN)   "Onto as a concept varies." # Hypothetical philosophical use (tagged: Onto/NNP)
'upon NOUN\tpreloaded/ententen21_tt31\t[lemma="upon"][tag="N.*"]\n'
On line 128
[word="upon"][pos="NN|NNS|NNP|NNPS"]  // All noun subtypes
'towards NOUN\tpreloaded/ententen21_tt31\t[lemma="toward"][tag="N.*"]\n'
On line 129
[lemma="towards"] [pos="NN.*"]
'sentence without commas\tpreloaded/ententen21_tt31\t<s/> !containing [word==","]\n'
On line 130
<s> []* </s> without [word=","|word=";"]
'sentence with colon\tpreloaded/ententen21_tt31\t<s/> containing [word==":"]\n'
On line 131
<s> []{0,150} [word=":"] []{0,150} </s>
'sentence with semicolon\tpreloaded/ententen21_tt31\t<s/> containing [word==";"]\n'
On line 132
// Find entire sentences containing at least one semicolon<s> []*? [word=";"] []*? </s>
'sentence starting with capitalized word\tpreloaded/ententen21_tt31\t<s> [word="[[:upper:]].+"]\n'
On line 133
<s> [word="[A-Z][A-Za-z]*"]    # Stricter version (letters only)
'sentence ending with proper noun\tpreloaded/ententen21_tt31\t[tag="NP|NPS"] </s>\n'
On line 134
within <s/>:   [upos="PROPN"]     // Match proper nouns (Universal Dependencies)  >> ( [upos="PUNCT"]){0,2}  // Allow 0-2 trailing punctuation tokens  :s :s @[s:end]   // Anchor to sentence end
'sentence beginning with adverb then comma\tpreloaded/ententen21_tt31\t<s> [tag="RB.*"][word==","]\n'
On line 135
dom(node, sent_start) & [pos="RB.*"] . [word=","]
'paragraph containing a year\tpreloaded/ententen21_tt31\t<p/> containing [word="\\d{4}"]\n'
On line 136
<paragraph> contains [word="\d{4}"]
'paragraph without digits\tpreloaded/ententen21_tt31\t<p/> !containing [word=".*\\d.*"]\n'
On line 137
<p>[word !=".*[0-9].*"]*</p>
'sentences inside docs genre=news\tpreloaded/ententen21_tt31\t<s/> within <doc genre=="news"/>\n'
On line 138
<s> within <doc @genre="news"/>
'sentences with no capitalized token\tpreloaded/ententen21_tt31\t<s/> !containing [word="[[:upper:]].*"]\n'
On line 139
// ANNIS/PAULA example: Combine token-level regex and structural negation  // (Note: ANNIS uses German-style REGEX operators)  NOT node & tok=/^[A-Z].*/
'quotation spans lacking nouns (<9 tokens) in one sentence\tpreloaded/ententen21_tt31\t([word="\\""][word!="\\""]{1,8}[word="\\""] !containing [tag="N.*"]) within <s/>\n'
On line 140
( [!pos="NN|NNS|NNP|NNPS" | pos=","|"."|"''"|"``"] ){0,6}
'climate change in one sentence\tpreloaded/ententen21_tt31\t[lemma="climate"][lemma="change"] within <s/>\n'
On line 141
<s/> "climate" "change" </s>
'data-driven or data driven\tpreloaded/ententen21_tt31\t[word=="data-driven"] | ([word="data"][word="driven"])\n'
On line 142
[word="data"][word="-"][word="driven"] | ([word="data"] [word="driven"])
'on the one hand ... on the other hand\tpreloaded/ententen21_tt31\t[word="on"][word="the"][word="one"][word="hand"][]{1,8}[word="on"][word="the"][word="other"][word="hand"]\n'
On line 143
"on" "the" "one" "hand" []{1,50} "on" "the" "other" "hand"
'repeated bigram A B ... A B within 6 tokens\tpreloaded/ententen21_tt31\t1:[] 2:[] []{0,6} 3:[] 4:[] & 1.word=3.word & 2.word=4.word\n'
On line 144
// Find repeated bigram 'X Y' with ≤6 tokens between occurrences [word] as a [word] as b   // First bigram (tokens A B)[]{0,5}                   // 0-5 tokens between bigrams (ensures ≤6 tokens gap)[word=a] [word=b]         // Second bigram (repeat of A B)
'two identical adjacent words\tpreloaded/ententen21_tt31\t1:[] 2:[] & 1.word = 2.word\n'
On line 145
annis  node & node & #1 . #2 & #1.word = #2.word
'two adjacent tokens with same lemma\tpreloaded/ententen21_tt31\t1:[] 2:[] & 1.lemma = 2.lemma\n'
On line 146
[lemma] as t1 [lemma=t1.lemma]
'coordinated adjectives sharing lemma\tpreloaded/ententen21_tt31\t1:[tag="J.*"][tag="CC"] 2:[tag="J.*"] & 1.lemma = 2.lemma\n'
On line 147
[upos="ADJ"] [word=","]? [upos="CCONJ" & lemma=("and"|"or")] [upos="ADJ"]
'coordinated nouns with different lemmas\tpreloaded/ententen21_tt31\t1:[tag="N.*"][tag="CC"] 2:[tag="N.*"] & 1.lemma != 2.lemma\n'
On line 148
[tag="NOUN" & lemma]  [tag="PUNCT"]?  [tag="CCONJ" & lemma="and"|lemma="or"]  [tag="PUNCT"]?  [tag="NOUN" & lemma != "\1"]
'adjective not followed by noun\tpreloaded/ententen21_tt31\t[tag="J.*"][tag!="N.*"]\n'
On line 149
[pos = "JJ"] !([pos = "NN.*"])   # Penn Treebank (adjective → JJ, nouns → NN/NNS/NNP/NNPS)
'verb not preceded by determiner\tpreloaded/ententen21_tt31\t[tag!="DT"][tag="V.*"]\n'
On line 150
[! tag="DT" & ! tag=","] [tag!=","]* [tag="V.*"]
'present that is not a verb\tpreloaded/ententen21_tt31\t[word="present" & !tag="V.*"]\n'
On line 151
[word="(?i)present" & !tag="V.*"]
'object that is a noun not verb\tpreloaded/ententen21_tt31\t[lemma="object" & tag="N.*"]\n'
On line 152
[pos="N.*" & !lemma=".*verb.*"] # OR simpler, if verb/noun homographs are explicitly tagged:# [pos="N.*" & !pos="V.*"]
'record as noun only\tpreloaded/ententen21_tt31\t[lemma="record" & tag="N.*"]\n'
On line 153
[word="(?i)record" & (pos="NN.*")]  # Matches all noun tags (NN, NNS, NNP, NNPS)
'read as verb only\tpreloaded/ententen21_tt31\t[lemma="read" & tag="V.*"]\n'
On line 154
[lemma="read" & pos="V.*" & !pos="N.*"]
'exact token "U.S."\tpreloaded/ententen21_tt31\t[word=="U.S."]\n'
On line 155
[word="U.S."]
'colour/color spelling variants\tpreloaded/ententen21_tt31\t[lemma="colou?r"]\n'
On line 156
[word="[cC][oO][lL][oO][u]?[rR][sS]?"]
'centre/center variants\tpreloaded/ententen21_tt31\t[lemma="cent(er|re)"]\n'
On line 157
[word="(?i)(centre|center)"]
'organisation/organization variants\tpreloaded/ententen21_tt31\t[word="organi[sz]ation"]\n'
On line 158
[word="[Oo]rgani[sz]ation"]
'analyse/analyze variants\tpreloaded/ententen21_tt31\t[lemma="analys(e|z)"]\n'
On line 159
[lemma="analyze"]
'e-mail/email variants\tpreloaded/ententen21_tt31\t[word="e-?mail"]\n'
On line 160
(  [word="e[-]?mail" i]     // Single token: "email", "e-mail", "EMAIL", etc.  |  [word="e" i] [word="mail" i]                // Two tokens: "e mail", "E MAIL", etc.  |  [word="e" i] [word="[-]" ] [word="mail" i]  // Three tokens: "e - mail", "E - Mail", etc.)
'cooperate/co-operate variants\tpreloaded/ententen21_tt31\t[lemma="co-?operate"]\n'
On line 161
[word="co-?operat(?:e|es|ed|ing)" & pos="V.*"]
're-creation/recreation variants\tpreloaded/ententen21_tt31\t[lemma="re-?creation"]\n'
On line 162
[word="re-creation" | word="Re-creation" | word="RE-CREATION" | word="recreation" | word="Recreation" | word="RECREATION"]
'wellbeing/well-being variants\tpreloaded/ententen21_tt31\t[lemma="well-?being"]\n'
On line 163
# Single token forms (compound words/hyphenated)( [word="(?i)well\\-?being"] )# Two-token forms (no hyphen: "well being")| ( [word="(?i)well"] [word="(?i)being"] )# Three-token forms (hyphen separate: "well - being")| ( [word="(?i)well"] [word="-"] [word="(?i)being"] )
'healthcare / health care variants\tpreloaded/ententen21_tt31\t[lemma="healthcare"] | [lemma="health"][lemma="care"]\n'
On line 164
(  [lc="healthcare"]              |  // One-word (e.g., "Healthcare", "HEALTHCARE")  [lc="health-care"]             |  // Hyphenated (e.g., "Health-care")  ([lc="health"] [lc="care"])       // Two-words (e.g., "health care", "Health Care"))
'New York in any case\tpreloaded/ententen21_tt31\t[lc="new"][lc="york"]\n'
On line 165
[word="(?i)los"] [word="(?i)angeles"]
'United States in any case\tpreloaded/ententen21_tt31\t[lc="united"][lc="states"]\n'
On line 166
[word="(?i)united"] [word="(?i)states"]
'adjectives ending with -ious\tpreloaded/ententen21_tt31\t[lemma=".*ious" & tag="J.*"]\n'
On line 167
[word=".*ious" & pos="JJ"]
'verbs ending -ise/-ize\tpreloaded/ententen21_tt31\t[lemma=".*i[sz]e" & tag="V.*"]\n'
On line 168
[tag="V.*" & lemma=".*[iI][sSzZ][eE]$"]
'nouns ending -tion\tpreloaded/ententen21_tt31\t[lemma=".*tion" & tag="N.*"]\n'
On line 169
[word="(?i).*tion$" & upos="NOUN"]
'agentive nouns ending -er/-or\tpreloaded/ententen21_tt31\t[lemma=".*(er|or)" & tag="N.*"]\n'
On line 170
[ ( lemma = ".*er" | lemma = ".*or" ) & (pos = "NN" | pos = "NNS") ]
'words starting micro-\tpreloaded/ententen21_tt31\t[word="micro.*"]\n'
On line 171
[word="[Mm]icro.*" & pos="N.*"]   // Only nouns
'words ending -ology\tpreloaded/ententen21_tt31\t[word=".*ology"]\n'
On line 172
[word=".*[oO]logy$"]
'Title Case tokens\tpreloaded/ententen21_tt31\t[word=[[:upper:]][[:lower:]]+]\n'
On line 173
[word="\p{Lu}\p{Ll}*"]  # Works in Unicode-aware tools like Sketch Engine
'lowercase-only tokens\tpreloaded/ententen21_tt31\t[word="[[:lower:]]+"]\n'
On line 174
[word="[a-z]+"]
'uppercase-only tokens\tpreloaded/ententen21_tt31\t[word="[[:upper:]]+"]\n'
On line 175
[word="^[A-Z]+$"]
'US or U.S. as regex\tpreloaded/ententen21_tt31\t[word=(US|U\\.S\\.)]\n'
On line 176
[word="(?i)U\.?S\.?"]
'tokens not a dot (exact)\tpreloaded/ententen21_tt31\t[word!="."]\n'
On line 177
[word != "."]
'tokens lexicographically >= m\tpreloaded/ententen21_tt31\t[word>="m"]\n'
On line 178
[word=".*" & lc >= "m"]
'tokens lexicographically < m\tpreloaded/ententen21_tt31\t[word<"m"]\n'
On line 179
[word="[\\x00-\\x6C].*"]
'verbs within documents topic=tech\tpreloaded/ententen21_tt31\t[tag="V.*"] within <doc topic=".*tech.*"/>\n'
On line 180
[tag="V.*"] [tag="V.*"] within <doc topic="tech"/>
'sentences not containing digits\tpreloaded/ententen21_tt31\t<s/> !containing [word=".*\\d.*"]\n'
On line 181
s; :: without [word ~ "[0-9]"];
'nouns outside quotations\tpreloaded/ententen21_tt31\t[tag="N.*"] !within ([word="\\""][]{1,30}[word="\\""] within <s/>)\n'
On line 182
[pos="N.*"] within c without q
'paragraphs not containing proper nouns\tpreloaded/ententen21_tt31\t<p/> !containing [tag="NP.*"]\n'
On line 183
<paragraph> not containing [pos = "NNP|NNPS"]
'tokens between quotes not verbs\tpreloaded/ententen21_tt31\t([word="\\""][word!="\\""]{1,10}[word="\\""] !containing [tag="V.*"]) within <s/>\n'
On line 184
### Key Components:1. `"` : Matches quote symbols (adjust to
'thesaurus: metals around corrosion +-4\tpreloaded/ententen21_tt31\t(meet ~"copper-n" [lemma="corrosion"] -4 4)\n'
On line 185
(  [lemma="aluminum" | lemma="copper" | lemma="gold" | lemma="iron" | lemma="lead"    | lemma="magnesium" | lemma="nickel" | lemma="silver" | lemma="steel" | lemma="tin" | lemma="zinc"]  []{0,4}  [lemma="corrosion"])|(  [lemma="corrosion"]  []{0,4}  [lemma="aluminum" | lemma="copper" | lemma="gold" | lemma="iron" | lemma="lead"    | lemma="magnesium" | lemma="nickel" | lemma="silver" | lemma="steel" | lemma="tin" | lemma="zinc"])
'thesaurus: vegetables after chop within 0–2\tpreloaded/ententen21_tt31\t[lemma="chop"][]{0,2} ~"carrot-n"\n'
On line 186
"thesaurus" [lemma="vegetable"] []{0,2} "chop"
'thesaurus: 20 similar to city-n\tpreloaded/ententen21_tt31\t~20"city-n"\n'
On line 187
word:sim("city", 20, "n")
'invest followed by renewable-like within 3\tpreloaded/ententen21_tt31\t[lemma="invest"][]{0,3} ~"renewable-n"\n'
On line 188
[lemma="invest"] []{0,2} [lemma="renewable" & pos="N.*|J.*"] - Optional `pos` filter restricts matches to nouns/adjectives  - Replace `N.*|J.*` with regex for narrower POS tags (e.g., `NOUN`)
'contact followed by doctor-like within 2\tpreloaded/ententen21_tt31\t[lemma="contact"][]{0,2} ~"doctor-n"\n'
On line 189
[word="contact"] []{0,2} [word="doctor" | word="doctors" | word="Dr" | word="Dr."]
'reduce near emission-like (+-5)\tpreloaded/ententen21_tt31\t(meet [lemma="reduce"] ~"emission-n" -5 5)\n'
On line 190
[lemma="reduce"] []{0,4} [word="[Ee][Mm][Ii][Ss][Ii][Oo][Nn].*"]|[word="[Ee][Mm][Ii][Ss][Ii][Oo][Nn].*"] []{0,4} [lemma="reduce"]
'noun within 2 tokens of adjective\tpreloaded/ententen21_tt31\t(meet [tag="N.*"] [tag="J.*"] -2 2)\n'
On line 191
(  [upos="ADJ"] []{0,2} [upos="NOUN"]   // Adj followed by noun (0, 1, or 2 tokens apart)) | (  [upos="NOUN"] []{0,2} [upos="ADJ"]   // Noun followed by adj (0, 1, or 2 tokens apart))
'verb within 1–4 tokens of noun to the right\tpreloaded/ententen21_tt31\t(meet [tag="V.*"] [tag="N.*"] 1 4)\n'
On line 192
[tag="N.*"] ([]){0,3} [tag="V.*"]
'adjectives within 2–5 tokens of noun on left\tpreloaded/ententen21_tt31\t(meet [tag="J.*"] [tag="N.*"] -5 -2)\n'
On line 193
[pos="NOUN"] []{1,4} [pos="ADJ"]
'Nouns near was/were and adjectives near be\tpreloaded/ententen21_tt31\t(union (meet [tag="N.*"] [word=="was|were"] -2 2) (meet [tag="J.*"] [lemma="be"] -2 2))\n'
On line 194
(  [lemma="be"]    []{0,5}    [pos="JJ|JJR|JJS"]  )  |  (    [pos="JJ|JJR|JJS"]    []{0,5}    [lemma="be"]  )
'Markers like (1) (2) ...\tpreloaded/ententen21_tt31\t[word=="("][word="\\d+"][word==")"]\n'
On line 195
[word="("] [word="[0-9]+"] [word=")"]
'dash-only tokens\tpreloaded/ententen21_tt31\t[word="-+"]\n'
On line 196
[word="^[\-–—]+$"]
'commas inside parentheses\tpreloaded/ententen21_tt31\t[word=="("][word=","][word==")"]\n'
On line 197
// Find commas occurring inside parentheses// Basic approach: Sequence with proximity constraints[word="("] []{1,100} [word=","] []{1,100} [word=")"]// Variant with token properties (adjust based on corpus tags)[word="(" & tag="("] [tag!=")" & tag!="("]{1,200} [word="," & tag=","] [tag!=")" & tag!="("]{1,200} [word=")" & tag=")"]
'proper noun + year\tpreloaded/ententen21_tt31\t[tag="NP"][word="\\d{4}"]\n'
On line 198
[pos = "NNP|NNPS"]+ [pos = "CD" & word = "[0-9]{4}|'[0-9]{2}"]
'please + base verb\tpreloaded/ententen21_tt31\t[lemma="please"][tag="V[BHV]"]\n'
On line 199
[word="please" & (pos="UH"|"RB")] []{0,2} [lemma=".*" & pos="VB"]
'so that sequences\tpreloaded/ententen21_tt31\t[word="so"][word="that"]\n'
On line 200
[word="[Ss]o" & tag="R.*"] []{0,2} [lemma="that" & tag="IN|C.*"]
'in case sequences\tpreloaded/ententen21_tt31\t[word="in"][word="case"]\n'
On line 201
[word="in"][word="case"][tag!="VBN"]{0,14}[tag="VBN"]
'as long as sequences\tpreloaded/ententen21_tt31\t[word="as"][word="long"][word="as"]\n'
On line 202
/* Ensure words are adjacent */   "as" "long" "as" within 3 tokens;     /* Restrict POS (e.g., all as conjunctions) */   [pos="CS"] [pos="AD.*"] [pos="CS"]
'modal + not + base verb\tpreloaded/ententen21_tt31\t[word="can|could|may|might|must|shall|should|will|would"][lemma="not"][tag="V[BHV]"]\n'
On line 203
[tag="MD"] [tag="RB" & word="not|n't"] [tag="VB"]
'Word Sketch: modifiers of policy-n\tpreloaded/ententen21_tt31\t[ws("policy-n","modifiers of \\"%w\\"",".*")]\n'
On line 204
[lemma="policy" & pos="N.*"] :: deprel="amod|nn|compound"
'Word Sketch: objects of approve-v\tpreloaded/ententen21_tt31\t[ws("approve-v",".*objects of \\"%w\\"",".*")]\n'
On line 205
[lemma="approve" & pos="VERB"] [](0,3) ?[deprel="obj"|"dobj"]
'Word Sketch: subjects of increase-v\tpreloaded/ententen21_tt31\t[ws("increase-v",".*subjects of \\"%w\\"",".*")]\n'
On line 206
([lemma="increase" & pos="V.*"] >[deprel="nsubj.*"] [] ) within s
'Word Sketch: decision-n as object of make-v\tpreloaded/ententen21_tt31\t[ws("decision-n",".*object.*","make-v")]\n'
On line 207
[lemma="make" & cpos="V"] >Obj [lemma="decision" & cpos="N"]
'Word Sketch: test-n modified by blood-n\tpreloaded/ententen21_tt31\t[ws("test-n",".*modifiers of \\"%w\\"","blood-n")]\n'
On line 208
[lemma="test" & pos="NOUN"] >>[deprel="compound"] [lemma="blood" & pos="NOUN"]
'Word Sketch: any relation of climate-n mentioning change\tpreloaded/ententen21_tt31\t[ws("climate-n",".*","change.*")]\n'
On line 209
> [lemma="climate" & tag="N.*"][]{0,5}[lemma="change"]>
'Word Sketch: verbs with %w as subject\tpreloaded/ententen21_tt31\t[ws(".*","verbs with \\"%w\\" as subject",".*-v")]\n'
On line 210
// Includes passive subjects like "was seen by %w"   [lemma="%w" & tag="N.*"] >[deprel="sb|nsubj|nsubj:pass|agent"] [tag="V.*"]
'car in English where German segment has Auto\tpreloaded/europarl7_en\t[word="car"] within europarl7_de_1: [word="Auto"]\n'
On line 211
[word="car" & aligned.id=de:.*Auto.*]
'house in English where French segment has maison\tpreloaded/europarl7_en\t[word="house"] within europarl7_fr: [word="maison"]\n'
On line 212
// Finds English segments with "house" aligned to French segments containing "maison"[word="house" & lang="en"] :a: [word="maison" & lang="fr"]
'Find a sentence consisting of as many words as is the meaning of life.\tpreloaded/ententen21_tt31\t<s> []{42} <s/>\n'
On line 213
<s/> [tag!="Z"]{42} []*? </s>   // "Z" = punctuation/symbols
'Find a sentence having as many words as the meaning of life.\tpreloaded/ententen21_tt31\t<s> []{42,} <s/>\n'
On line 214
<sentence>  [lemma=".*"]{42} </sentence>
'Find a sentence having exactly as many words as the meaning of life.\tpreloaded/ententen21_tt31\t<s> []{42} <s/>\n'
On line 215
within <s/>; :: length=42 # CQP-style
'Find a sequence of as many tokens as is the meaning of life.\tpreloaded/ententen21_tt31\t[]{42}\n'
On line 216
[pos="NOUN"]{42}   # 42 consecutive nouns
'Find examples of subject and predicate. The subject should be a noun phrase.\tpreloaded/ententen21_tt31\t[ws(".*", "verbs with \\"%w\\" as subject", ".*-v")]\n'
On line 217
<s>{ NP: []* [deprel="nsubj"] VP: [tag="V.*"]+ }</s>
'Find examples of subject and predicate.\tpreloaded/ententen21_tt31\t[ws(".*", "verbs with \\"%w\\" as subject", ".*-v")]\n'
On line 218
> <s> <np> []* <vp> </s>>
'Give me all the objects of a verb test.\tpreloaded/ententen21_tt31\t[ws("test-v", "objects of \\"%w\\"", ".*")]\n'
On line 219
sql      {lemma="test" pos="VERB"} >(obj | obl) []
'Give me all the objects of the verb "test".\tpreloaded/ententen21_tt31\t[ws("test-v", "objects of \\"%w\\"", ".*")]\n'
On line 220
// CQL query to find direct objects of all forms of the verb "test"// Assumes dependency annotation (e.g., Universal Dependencies)[lemma="test" & pos="VERB"]> [deprel="obj"]
'How do I find direct speech?\tpreloaded/ententen21_tt31\t[word="\\""] [word!="\\""]+ [word="\\""] within <s/>\n'
On line 221
// To capture direct speech in annotation-aware corpora (e.g., Sketch Engine)(  // Case 1: Reporting clause BEFORE speech (e.g., He said: "...")  [lemma = "say"|"ask"|"shout"|"declare"|"reply"|"explain"]   []{0,3} [tag=":"]?   []{0,3} "[word="\"|“"]"     |     // Case 2: Reporting clause AFTER speech (e.g., "...", he said)  "[word="\"|“"]"   [][word!="\"|“|”"]+   "[word="\"|”"]"   []{0,3} [tag=","]?   [lemma = "say"|"ask"|"add"|"whisper"|"answer"])
'How to find all noun phrases?\tpreloaded/ententen21_tt31\t[tag="J.*"]{0,5} [tag="N.*"]\n'
On line 222
[dependencyRelation="nsubj"] // Finds NPs acting as subjects
'I need to find all examples of direct speech.\tpreloaded/ententen21_tt31\t[word="\\""] [word!="\\""]+ [word="\\""] within <s/>\n'
On line 223
[pos="PRP" | lemma="be"][]{0,3}[lemma="say" | lemma="ask" | lemma="shout"][]{0,3}[word="\""][]{0,100}[word="\""]
'I would like to filter out all simple prepositions in a corpus.\tpreloaded/ententen21_tt31\t<s/> !containing [tag="IN"]\n'
On line 224
[pos="VB"] [pos!="IN"]
'Please give me all the objects of a verb test.\tpreloaded/ententen21_tt31\t[ws("test-v", "objects of \\"%w\\"", ".*")]\n'
On line 225
[lemma="test" & tag="V.*"] >[deprel="obj"]
'Hyphenated compounds with ≥3 parts (e.g., state-of-the-art)\tpreloaded/ententen21_tt31\t[word="[A-Za-z]+(-[A-Za-z]+){2,}"]\n'
On line 226
(  [word = ".+-.+-.+"]  // Monolithic tokens (at least 2 hyphens = 3 parts))|(  [word != "-"]        // Split-token sequences: [word] [-] [word] [-] [word]...  [word = "-"]   [word != "-"]   [word = "-"]   [word != "-"]   ( [word = "-"] [word != "-"] )*  // Optional extra parts)|(  [word ~ "^[^-].*"]   // Attached-hyphens: token not starting with hyphen  [word ~ "^-[^-]+$"]{2,} // ≥2 tokens: hyphen + non-hyphen chars (e.g., "-word"))
'Prefix re-, un-, de-, (optionally hyphenated)\tpreloaded/ententen21_tt31\t[word="(re|un|de)-?[a-z]+"]\n'
On line 227
[word="/(re|un|de)-?.*/"]
'Prefix re-, un-, de- (must be hyphenated)\tpreloaded/ententen21_tt31\t[word="(re|un|de)-[a-z]+"]\n'
On line 228
[word="(re|un|de)-\\w+"]  \\ Requires ≥1 char after hyphen (e.g., "re-do")
'Case-insensitive match of "Internet"\tpreloaded/ententen21_tt31\t[lc="internet"]\n'
On line 229
"[Dd]ark" [word="[Nn]et.*"]
'The noun "policy".\tpreloaded/ententen21_tt31\t[lempos="policy-n"]\n'
On line 230
[lemma="policy" & pos="N.*"]
'Coordinating prepositions after "hand".\tpreloaded/ententen21_tt31\t[lemma="hand"][word="in|over|out"]\n'
On line 231
[lemma="hand"] [pos="IN" | tag="CC"]
'Verb–particle constructions with short gaps\tpreloaded/ententen21_tt31\t[tag="V.*"] []{,2} [tag="RP"]\n'
On line 232
[pos="V.*"] [pos!="V.*"]{0,5} [word="off"|"up"|"in"|"out"|...]
'Examples of similes\tpreloaded/ententen21_tt31\t[lemma="like"] [word="the|a|an"]? [tag="N.*"]) | ([word="as"] [tag="J.*|RB.*"] [word="as"]\n'
On line 233
(  [word="as" & tag="RB"] [tag="JJ.*"]  # "as [Adjective]..." (e.g., "as bright")  |  [word="as"] [tag="JJ.*"] [word="as"] # "as [Adjective] as..." (e.g., "as bright as")  |  [tag="JJ.*"] [word="as"]             # "[Adjective] as..." (e.g., "bright as")  |  [word="like" & tag="IN"]             # "like..." (e.g., "like the sun"))
'Coordinated nouns captured as the whole sentence\tpreloaded/ententen21_tt31\t<s/> containing [tag="N.*"] [tag="CC"] [tag="DT"]? [tag="N.*"]\n'
On line 234
within S;// Match coordinated noun patterns:(  [pos="NOUN"]+                 // Sequence of 1+ nouns  ([pos="PUNCT"&form=","]       // Optional commas or CCONJ   | [pos="CCONJ"&lemma="and|or"])  []{0,2}                       // Allow 0-2 tokens between)* [pos="CCONJ"&lemma="and|or"]    // Mandatory conjunction[]?                             // Optional token (e.g., punctuation)[pos="NOUN"]                    // Final noun
'Email domains like .edu or .org\tpreloaded/ententen21_tt31\t[word=".*@.*\\.(edu|org)"]\n'
On line 235
| [word=".*@.*\\.[cC][oO][mM]"]  // .com  | [word=".*@.*\\.[gG][oO][vV]"]  // .gov
'Hex color codes\tpreloaded/ententen21_tt31\t[word="#([0-9A-Fa-f]{3}|[0-9A-Fa-f]{6})"]\n'
On line 236
regex   [0-9a-f]{3}  → 3-digit (e.g., #f00)     [0-9a-f]{4}  → 4-digit (with alpha, e.g., #f00a)     [0-9a-f]{6}  → 6-digit (e.g., #ff0000)     [0-9a-f]{8}  → 8-digit (with alpha, e.g., #ff0000ff)
'IPv4 addresses\tpreloaded/ententen21_tt31\t[word="([12]?[0-9]?[0-9]\\.){3}[12]?[0-9]?[0-9]"]\n'
On line 237

'Usernames beginning with @\tpreloaded/ententen21_tt31\t[word="@\\w+"]\n'
On line 238
[word="\@[a-zA-Z0-9_]+"]  // Alphanumeric + underscores only
'Roman numerals I–X\tpreloaded/ententen21_tt31\t[word="(I|II|III|IV|V|VI|VII|VIII|IX|X)"]\n'
On line 239
[word="(?i)^(I|II|III|IV|V|VI|VII|VIII|IX|X)$"]
'A month name followed by a year\tpreloaded/ententen21_tt31\t[lemma="january|february|march|april|may|june|july|august|september|october|november|december"][word="\\d{4}"]\n'
On line 240
[word="(?i)(january|february|...|dec)"] [word="\d{4}"]
'A weekday followed by a comma\tpreloaded/ententen21_tt31\t[lemma="monday|tuesday|wednesday|thursday|friday|saturday|sunday"][word==","]\n'
On line 241
[word="Monday"|"monday"|"Tuesday"|"tuesday"|...] [word=","]
'Any sentence that contains negation.\tpreloaded/ententen21_tt31\t<s/> containing [lemma="not"]\n'
On line 242
([word="(?i)(not|no|never|barely|scarcely|hardly)" | ...]) within s
'Any token followed by a noun in a sentence.\tpreloaded/ententen21_tt31\t[][tag="N.*"] within <s/>\n'
On line 243
[] [pos="NOUN"] [pos="NOUN"]
'Any word followed by a noun in one sentence.\tpreloaded/ententen21_tt31\t[][tag="N.*"] within <s/>\n'
On line 244
[][lemma] [lemma] & [upos != "PUNCT"][] [upos = "NOUN"]
'Any word followed by a noun.\tpreloaded/ententen21_tt31\t[][tag="N.*"]\n'
On line 245
"aleyküm" within s [pos="NOUN"]
'Find adjectives followed by nouns.\tpreloaded/ententen21_tt31\t[tag="J.*"][tag="N.*"]\n'
On line 246
[pos="JJ"] [pos="NN"]
'Find all nouns with the verb to be at a distance of 3 tokens to the left or right and find all adjectives with the verb to be at a distance of 2 tokens to the left or right.\tpreloaded/ententen21_tt31\t(union (meet [tag="N.*"] [tag="VB.*"] -3 3) (meet [tag="J.*"] [tag="VB.*"] -2 2))\n'
On line 247
(    (      [lemma="be"] [] [] [] [pos="NOUN"]  |  // be 3 tokens LEFT of noun      [pos="NOUN"] [] [] [] [lemma="be"]     // be 3 tokens RIGHT of noun    ) |    (      [lemma="be"] [] [] [pos="ADJ"]    |    // be 2 tokens LEFT of adjective      [pos="ADJ"] [] [] [lemma="be"]         // be 2 tokens RIGHT of adjective    )  )
'Find sentences that begin with the word An\tpreloaded/ententen21_tt31\t<s> [word="An"]\n'
On line 248
<s/> containing [word="An" %c]
'Find sentences that begin with the word The\tpreloaded/ententen21_tt31\t<s> [word="The"]\n'
On line 249
[word="The" & pos="DT"]::sentence@1  # DT = determiner
'Find sentences that begin with the word "The"\tpreloaded/ententen21_tt31\t<s> [word="The"]\n'
On line 250
[word="The" & %B=1]     # If %B=1 marks sentence start
'Find the word however followed by a comma\tpreloaded/ententen21_tt31\t[word="however"] [word=","]\n'
On line 251
[word="[Hh]owever"] [word=","]
'Find the word however not followed by comma\tpreloaded/ententen21_tt31\t[word="however"] [word!="," ]\n'
On line 252
[word="however"] ( [word!=","] | %c )
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 253
[word="19[0-9][0-9]"] [word="[aA].[dD]."]  # Escape dots depending on tool
'Find examples of noun phrases consisting of a minimum of three tokens.\tpreloaded/ententen21_tt31\t[tag="J.*|N.*"]{2,} [tag="N.*"]\n'
On line 254
// IOB-style chunking (e.g., B-NP/I-NP)  [chunk="B-NP"] [chunk="I-NP"]{2,}
'find patterns: "noun|adjective" or "adjective|noun\tpreloaded/ententen21_tt31\t([tag="N.*"][tag="J.*"]) | ([tag="J.*"][tag="N.*"])\n'
On line 255
[tag="NOUN"] []{0,2} [tag="ADJ"] | [tag="ADJ"] []{0,2} [tag="NOUN"]
'Phrase "no longer" or "no more"\tpreloaded/ententen21_tt31\t[lemma="no"][word="longer|more"]\n'
On line 256
[ word="(?i)no" ] ( [ word="(?i)longer" ] | [ word="(?i)more" ] )
'Sentences ending with a question mark\tpreloaded/ententen21_tt31\t[word=="?"] </s>\n'
On line 257
sent include [word="\?"] anchornode & #node _last
'Paragraphs that contain a 4-digit year.\tpreloaded/ententen21_tt31\t[word="[0-9]{4}"] within <p/>\n'
On line 258
p contains [word="[12][0-9]{3}" & tag="CD"]  # CD = cardinal number
'NP bigrams\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]{2}\n'
On line 259
# Only ADJ+NOUN or NOUN+NOUN([tag="JJ.*|NN.*"] [tag="NN.*"])
'Nouns inside quotation spans\tpreloaded/ententen21_tt31\t[tag="N.*"] within [word="\\""] []{1,5} [word="\\""]\n'
On line 260
within <quote> [pos="N.*"]
'Quatation marks not containing a noun in one sentence.\tpreloaded/ententen21_tt31\t([word="\\""][word!="\\""]{5,}[word="\\""] !containing [tag="N.*"]) within <s/>\n'
On line 261
[word=("\""|"“")] [pos!~"NN.*"]* [word=("\""|"”")]
'Negation near change verbs increase/decrease.\tpreloaded/ententen21_tt31\t(meet [lemma="increase" | lemma="decrease" & tag="V.*"] [lemma="not|never|none|neither"] -1 1)\n'
On line 262
([word="not"|word="never"|word~".*n't" & pos="RB"] // adverbs   |    [word="no" & pos!="DT"]) // exclude determiners
'Risk with a mitigate verb somewhere to its left (1–5 tokens away)\tpreloaded/ententen21_tt31\t(meet [lemma="risk"] [lemma="mitigate"] -5 -1)\n'
On line 263
[] [lemma="mitigate" & pos="V.*"] <: [word="Risk"]
'Coordinated adjectives where the lemmas are the same.\tpreloaded/ententen21_tt31\t1:[tag="J.*"] [tag="CC"] 2:[tag="J.*"] & 1.lemma = 2.lemma\n'
On line 264
(  [pos="ADJ" & lemma=$L]   # First adjective (capture lemma as $L)  [word=","]                # Required comma  [pos="ADJ" & lemma=$L]    # Second adjective with SAME lemma)|(  [pos="ADJ" & lemma=$L]   # First adjective  [word="and"|word="or"]    # Coordinating conjunction  [pos="ADJ" & lemma=$L]    # Second adjective with SAME lemma)|(  [pos="ADJ" & lemma=$L]   # First adjective  [word=","]                # Comma  [word="and"|word="or"]    # Coordinating conjunction  [pos="ADJ" & lemma=$L]    # Second adjective with SAME lemma)
'Immediate word repetitions\tpreloaded/ententen21_tt31\t1:[] 2:[] & 1.word = 2.word\n'
On line 265
[lc] \1
'Any relation of policy-n where the collocation mentions climate.\tpreloaded/ententen21_tt31\t[ws("policy-n",".*",".*climate.*")]\n'
On line 266
// CQL: Find dependency relationships for "policy" (noun) //      where the context includes "climate" within a 5-word window(  [lemma="policy" & tag="N.*" ]  // Match noun forms of "policy" (e.g., policy, policies)  -[deprel=/.*/]->   // Any outgoing dependency (e.g., nsubj, obj, amod)  [lemma="climate"]   // Dependency head/dependent is "climate")|// Search in reverse direction (if "climate" depends on "policy")(  [lemma="climate"]   -[deprel=/.*/]->   [lemma="policy" & tag="N.*"])|// Optional: Collocate "policy" with "climate" in proximity (if dependencies are unavailable)[lemma="policy" & tag="N.*"] within 5 words [lemma="climate"]
'Sentences where policy-n has a collocation reform-v in an “object-like” relation, and it’s preceded by governmental within 2 tokens.\tpreloaded/ententen21_tt31\t[word="governmental"] []{0,2} [ws("policy-n",".*object.*","reform-v")]\n'
On line 267
(  [word="governmental" & pos="ADJ"]  // Capture 'governmental' as adjective  []{0,2}                            // Allow 0-2 tokens gap  [lemma="policy" & pos="NOUN"]      // Target noun 'policy') >>[func="obj" | func="iobj" | func="obl"]  // Dependency relation: object-like[lemma="reform" & pos="VERB"]         // Verb 'reform' as governing node
'"see" followed by a word similar to doctor-like profession.\tpreloaded/ententen21_tt31\t[lemma="see"] [tag="DT"]? ~10"doctor-n"\n'
On line 268
[lemma="see"] ([lemma="doctor"] | [lempos="N.*|adj.*" & word=".*(physician|surgeon|nurse|clinician|specialist)|practitioner|therapist"])
'Words similar to noun renewable with invest 0–3 to the left.\tpreloaded/ententen21_tt31\t[lemma="invest"] []{0,3} ~"renewable-n"\n'
On line 269
[lemma="invest"] [word=".*"]{0,3} [lemma="renewable" & cpos="N.*"]
'Thousands separators\tpreloaded/ententen21_tt31\t[word="[0-9]{1,3}(,[0-9]{3})+"]\n'
On line 270
[word~".*\\d{1,3}([., \u00A0]\\d{3})+"];
'capitalized words not sentence-initial\tpreloaded/ententen21_tt31\t[word="[A-Z].*"] within !<s> []\n'
On line 271
<s/> []*? [word="[A-Z].+"] :c
'Any token.\tpreloaded/ententen21_tt31\t[]\n'
On line 272
[]{2}
'Find all verbs in the past tense.\tpreloaded/ententen21_tt31\t[tag="V.D"]\n'
On line 273
[tag="VB[DN]" & lemma="go"]  // Past tense forms of "go" (went/gone)
'Find any pronoun.\tpreloaded/ententen21_tt31\t[tag="PP.?|WP.?"]\n'
On line 274
[tag="PRON"]
'All-caps acronyms with 2+ letters\tpreloaded/ententen21_tt31\t[word="[A-Z]{2,}"]\n'
On line 275
[word="[A-Z][A-Z]+"]
'Ordinal numbers\tpreloaded/ententen21_tt31\t[word="\\d+(st|nd|rd|th)"]\n'
On line 276
[pos="ADJ" & tag="NumType=Ord"] # UD-style corpora
