'lemmas ending with -ment\tpreloaded/ententen21_tt31\t[lemma=".*ment"]\n'
On line 1
[lemma=".*ment"]
'tokens that are exactly semicolons\tpreloaded/ententen21_tt31\t[word==";"]\n'
On line 2
[word=";"]
'five-letter lowercase words\tpreloaded/ententen21_tt31\t[word="[[:lower:]]{5}"]\n'
On line 3
[lc="^.{5}$"]
'words starting with trans-\tpreloaded/ententen21_tt31\t[word="trans.*"]\n'
On line 4
[lemma="trans.*"]
'words ending with -able or -ible\tpreloaded/ententen21_tt31\t[word=".*[ai]ble"]\n'
On line 5
[lc=".*able|.*ible"]
'lemmas starting with micro- and ending with -scope\tpreloaded/ententen21_tt31\t[lemma="micro.*scope"]\n'
On line 6
[lemma="micro-.*-scope"]
'tokens that contain a hyphen\tpreloaded/ententen21_tt31\t[word=".*-.*"]\n'
On line 7
[word=".*-.*"]
'tokens that are only digits\tpreloaded/ententen21_tt31\t[word="\\d+"]\n'
On line 8
[word="^[0-9]+$"]
'tokens that are punctuation\tpreloaded/ententen21_tt31\t[word="[[:punct:]]+"]\n'
On line 9
[tag="\"|\\(|\\)|,|\\$|\\#|:|SENT"]
'any finite verb\tpreloaded/ententen21_tt31\t[tag="V[VBH][PZD]"]\n'
On line 10
[tag="V[BHV][DPZ]"]
'any common noun\tpreloaded/ententen21_tt31\t[tag="NN|NNS"]\n'
On line 11
[tag="N[^P].*"]
'any proper noun token\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]\n'
On line 12
[tag="NP.*"]
'wh-determiners\tpreloaded/ententen21_tt31\t[tag="WDT"]\n'
On line 13
[tag="WDT"]
'wh-adverbs\tpreloaded/ententen21_tt31\t[tag="WRB"]\n'
On line 14
[tag="WRB"]
'base adjectives\tpreloaded/ententen21_tt31\t[tag="JJ"]\n'
On line 15
[tag="JJ"]
'base adverbs\tpreloaded/ententen21_tt31\t[tag="RB"]\n'
On line 16
[tag="RB"]
'coordinating conjunction "and"\tpreloaded/ententen21_tt31\t[lemma=="and" & tag="CC"]\n'
On line 17
[word="and"]
'determiners \'a|an|the\'\tpreloaded/ententen21_tt31\t[lemma="a|an|the" & tag="DT"]\n'
On line 18
[lemma="a"] | [lemma="the"]
'comparatives ending by -er\tpreloaded/ententen21_tt31\t[word=".*er" & tag="JJR"]\n'
On line 19
[tag="JJR" & lc=".*er"]
'superlatives ending by -est\tpreloaded/ententen21_tt31\t[word=".*est" & tag="JJS"]\n'
On line 20
[tag="JJS"]
'comparatives not ending by -er\tpreloaded/ententen21_tt31\t[word!=".*er" & tag="JJR"]\n'
On line 21
[tag="JJR" & word !=".*er$"]
'superlatives not ending by -est\tpreloaded/ententen21_tt31\t[word!=".*est" & tag="JJS"]\n'
On line 22
[tag="JJS" & word != ".*est"]
'plural nouns ending with -ies\tpreloaded/ententen21_tt31\t[word=".*ies" & tag="NNS"]\n'
On line 23
[tag="NNS" & lc=".*ies"]
'plural nouns ending with -s\tpreloaded/ententen21_tt31\t[word=".*s" & tag="NNS"]\n'
On line 24
[tag="NNS" & word=".*s$"]
'verbs ending with -ed (past forms)\tpreloaded/ententen21_tt31\t[word=".*ed" & tag="V[VBH][DN]"]\n'
On line 25
[word=".*ed$"]
'contractions ending n\'t\tpreloaded/ententen21_tt31\t</g>[word="n\'t"]\n'
On line 26
[lc=".*n't"]
'tokens with an apostrophe\tpreloaded/ententen21_tt31\t[word=".*\'.*"]\n'
On line 27
[word=".*'"]
'currency symbols $ £ €\tpreloaded/ententen21_tt31\t[word="$|£|€"]\n'
On line 28
[tag="$"]
'tokens like (c) or (R)\tpreloaded/ententen21_tt31\t[word=="("][word="(c|C|r|R)"][word==")"]\n'
On line 29
[word="\\(c\\)"] | [word="\\(R\\)"]
'cardinal numbers with decimals\tpreloaded/ententen21_tt31\t[word="\\d+\\.\\d+" & tag="CD"]\n'
On line 30
[word="\\d+\\.\\d+"]
'numbers with percent sign\tpreloaded/ententen21_tt31\t[word="\\d+(\\.\\d+)?"][word="%"]\n'
On line 31
[tag="CD"] [word="%"]
'time like 7:30 pm\tpreloaded/ententen21_tt31\t[word="[1-2]?\\d:[0-5]\\d"][word="am|pm|AM|PM"]\n'
On line 32
[word="\d+:\d+"][word="pm"]
'sentence starts with a quote\tpreloaded/ententen21_tt31\t<s> [word="\\"|“|‘|\'"]\n'
On line 33
<s> ( [tag="\""] | [tag="'"] )
'sentence ends with an exclamation mark\tpreloaded/ententen21_tt31\t[word=="!"] </s>\n'
On line 34
<s> [word="!" & tag="SENT"] </s>
'tokens that are open parenthesis\tpreloaded/ententen21_tt31\t[word=="("]\n'
On line 35
[word=="("]
'tokens that are close parenthesis\tpreloaded/ententen21_tt31\t[word==")"]\n'
On line 36
[tag=")"]
'bracketed content up to 7 tokens\tpreloaded/ententen21_tt31\t[word=="("][]{0,7}[word==")"]\n'
On line 37
[ ]{1,7}
'quoted spans up to 6 tokens\tpreloaded/ententen21_tt31\t[word="\\""][]{0,6}[word="\\""]\n'
On line 38
([word="\""] [ ]{0,4} [word="\""]) | ([word="'"] [ ]{0,4} [word="'"])
'‘Mr.’ or ‘Ms.’ before a name\tpreloaded/ententen21_tt31\t[word="Mr\\.|Ms\\.|Mrs\\.|Dr\\."][tag="NP"]\n'
On line 39
([word="Mr."][tag="NP"]) | ([word="Ms."][tag="NP"])
'personal pronoun followed by be\tpreloaded/ententen21_tt31\t[tag="PP"][lemma="be"]\n'
On line 40
[tag="PP"] [tag="VB"]
'proper noun followed by be\tpreloaded/ententen21_tt31\t[tag="NP"][lemma="be"]\n'
On line 41
[tag="NP" | tag="NPS"] [lemma="be"]
'noun preceded by exactly one adjective\tpreloaded/ententen21_tt31\t[tag="J.*"][tag="N.*"]\n'
On line 42
[tag="J.*"][tag="N.*"]
'noun preceded by two adjectives\tpreloaded/ententen21_tt31\t[tag="J.*"]{2}[tag="N.*"]\n'
On line 43
[tag="JJ"][tag="JJ"][tag="N.*"]
'noun preceded by 0–3 adjectives\tpreloaded/ententen21_tt31\t[tag="J.*"]{0,3}[tag="N.*"]\n'
On line 44
[tag="J.*"]{0,3} [tag="N.*"]
'adverb immediately before an adjective\tpreloaded/ententen21_tt31\t[tag="RB.*"][tag="J.*"]\n'
On line 45
[tag="R.*"][tag="J.*"]
'adjective immediately before a verb\tpreloaded/ententen21_tt31\t[tag="J.*"][tag="V.*"]\n'
On line 46
[tag="J.*"] [tag="V.*"]
'verb immediately before a noun\tpreloaded/ententen21_tt31\t[tag="V.*"][tag="N.*"]\n'
On line 47
[tag="V.*"][tag="N.*"]
'determiner + adjective + noun\tpreloaded/ententen21_tt31\t[tag="DT"][tag="J.*"][tag="N.*"]\n'
On line 48
[tag="DT"] [tag="J.*"] [tag="N.*"]
'proper-noun bigrams\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]{2}\n'
On line 49
[tag="NP.*"] [tag="NP.*"]
'three-token proper-noun sequences\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]{3}\n'
On line 50
[tag="NP.*"] [tag="NP.*"] [tag="NP.*"]
'noun-noun compounds of length 3\tpreloaded/ententen21_tt31\t[tag="N.*"]{3}\n'
On line 51
[tag="N.*"] [tag="N.*"] [tag="N.*"]
'verb + particle (RP) with <3 gap\tpreloaded/ententen21_tt31\t[tag="V.*"][]{0,2}[tag="RP"]\n'
On line 52
[tag="V.*"] [ ]{0,2} [tag="RP"]
'verb + adverb + particle\tpreloaded/ententen21_tt31\t[tag="V.*"][tag="RB.*"][tag="RP"]\n'
On line 53
[tag="V.*"] [tag="RB.*"] [tag="RP"]
'be + not + adjective\tpreloaded/ententen21_tt31\t[lemma="be"][lemma="not"][tag="J.*"]\n'
On line 54
[lemma="be"] [word="not"] [tag="JJ.*"]
'do-support negation + base verb\tpreloaded/ententen21_tt31\t[lemma="do"][lemma="not"][tag="V[BHV]"]\n'
On line 55
[tag="VV"] [tag="RB"] [tag="VV"]
'want to + base verb\tpreloaded/ententen21_tt31\t[lemma="want"][lemma="to"][tag="V[BHV]"]\n'
On line 56
[word="want"][word="to"][tag="VB" | tag="VV"]
'need to + base verb\tpreloaded/ententen21_tt31\t[lemma="need"][lemma="to"][tag="V[BHV]"]\n'
On line 57
[lemma="need"] [tag="TO"] [tag="VV"]
'plan to + base verb\tpreloaded/ententen21_tt31\t[lemma="plan"][lemma="to"][tag="V[BHV]"]\n'
On line 58
[lemma="plan"][tag="TO"][tag="V[BHV]"]
'try to + base verb\tpreloaded/ententen21_tt31\t[lemma="try"][lemma="to"][tag="V[BHV]"]\n'
On line 59
[lemma="try"] [word="to"] [tag="V.*"]
'be going to + base verb\tpreloaded/ententen21_tt31\t[lemma="be"][lemma="going"][lemma="to"][tag="V[BHV]"]\n'
On line 60
[tag="VBP" | tag="VBZ" | tag="VBD"] [word="going"] [tag="TO"] [tag="VV"]
'have to + base verb\tpreloaded/ententen21_tt31\t[lemma="have"][lemma="to"][tag="V[BHV]"]\n'
On line 61
[tag="VH"] [tag="TO"] [tag="VV" | tag="VB"]
'used to + base verb\tpreloaded/ententen21_tt31\t[lemma="use"][lemma="to"][tag="V[BHV]"]\n'
On line 62
[word="used" & tag="VVD"] [word="to" & tag="TO"] [tag="VV"]
'would rather + base verb\tpreloaded/ententen21_tt31\t[word=="would"][word=="rather"][tag="V[BHV]"]\n'
On line 63
[word="would"] [word="rather"] [tag="V[BV]"]
'had better + base verb\tpreloaded/ententen21_tt31\t[word=="had"][word=="better"][tag="V[BHV]"]\n'
On line 64
[word="had"] [word="better"] [tag="VB|VV|VH"]
'prefer to + base verb\tpreloaded/ententen21_tt31\t[lemma="prefer"][lemma="to"][tag="V[BHV]"]\n'
On line 65
[lemma="prefer"] [tag="TO"] [tag="V[VB]"]
'ask NOUN to + base verb\tpreloaded/ententen21_tt31\t[lemma="ask"][tag="N.*"][lemma="to"][tag="V[BHV]"]\n'
On line 66
[tag="N.*"][word="to"][tag="VV"]
'tell NOUN to + base verb\tpreloaded/ententen21_tt31\t[lemma="tell"][tag="N.*"][lemma="to"][tag="V[BHV]"]\n'
On line 67
[lc="tell"] [tag="N.*"] [lc="to" & tag="TO"] [tag="VV"]
'allow PRON to + base verb\tpreloaded/ententen21_tt31\t[lemma="allow"][tag="PP|WP|WPZ"][lemma="to"][tag="V[BHV]"]\n'
On line 68
[tag="PP"] [tag="TO"] [tag="VB" | tag="VV" | tag="VH"]
'promise to + base verb\tpreloaded/ententen21_tt31\t[lemma="promise"][lemma="to"][tag="V[BHV]"]\n'
On line 69
[lemma="promise"] [word="to"] [tag="VB|VH|VV"]
'begin to + base verb\tpreloaded/ententen21_tt31\t[lemma="begin"][lemma="to"][tag="V[BHV]"]\n'
On line 70
[lemma="begin"][word="to" & tag="TO"][tag="VV"]
'continue to + base verb\tpreloaded/ententen21_tt31\t[lemma="continue"][lemma="to"][tag="V[BHV]"]\n'
On line 71
[lemma="continue"] [tag="TO"] [tag="V[BHV]"]
'seem to + base verb\tpreloaded/ententen21_tt31\t[lemma="seem"][lemma="to"][tag="V[BHV]"]\n'
On line 72
[lemma="seem"][tag="TO"][tag="VB"]
'happen to + base verb\tpreloaded/ententen21_tt31\t[lemma="happen"][lemma="to"][tag="V[BHV]"]\n'
On line 73
[lemma="happen"][tag="TO"][tag="VV"]
'appear to + base verb\tpreloaded/ententen21_tt31\t[lemma="appear"][lemma="to"][tag="V[BHV]"]\n'
On line 74
[lemma="appear"][tag="TO"][tag="VB"]
'be about to + base verb\tpreloaded/ententen21_tt31\t[lemma="be"][lemma="about"][lemma="to"][tag="V[BHV]"]\n'
On line 75
[tag="VB.*"] [word="about"] [word="to"] [tag="VV"]
'try not to + base verb\tpreloaded/ententen21_tt31\t[lemma="try"][lemma="not"][lemma="to"][tag="V[BHV]"]\n'
On line 76
[lemma="try"] [lemma="not"] [lemma="to"] [tag="VB|VV"]
'adjective with not\tpreloaded/ententen21_tt31\t[lemma="not"][tag="J.*"]\n'
On line 77
[word="not"] [tag="JJ.*"]
'noun with no\tpreloaded/ententen21_tt31\t[lemma="no"][tag="N.*"]\n'
On line 78
[tag="N.*"][word="no"]
'no + adjective + noun\tpreloaded/ententen21_tt31\t[lemma="no"][tag="J.*"]?[tag="N.*"]\n'
On line 79
[lemma="no"] [tag="J.*"] [tag="N.*"]
'not + verb within one token\tpreloaded/ententen21_tt31\t(meet [tag="V.*"] [lemma="not"] -1 1)\n'
On line 80
[word="not"] [tag="V.*"]
'verb within three tokens of risk\tpreloaded/ententen21_tt31\t(meet [tag="V.*"] [lemma="risk"] -3 3)\n'
On line 81
(meet [lemma="risk"] [tag="V.*"] -3 3)
'adjectives within two tokens of seem\tpreloaded/ententen21_tt31\t(meet [tag="J.*"] [lemma="seem"] -2 2)\n'
On line 82
(meet [tag="JJ.*"] [lemma="seem"] -2 2)
'noun within five tokens of increase\tpreloaded/ententen21_tt31\t(meet [tag="N.*"] [lemma="increase"] -5 5)\n'
On line 83
(meet [tag="N.*"] [lc="increase"] -5 5)
'union of verbs/adjectives near be\tpreloaded/ententen21_tt31\t(union (meet [tag="V.*"] [lemma="be"] -3 3) (meet [tag="J.*"] [lemma="be"] -2 2))\n'
On line 84
(union (meet [tag="V.*"] [lemma="be"] -2 2) (meet [tag="J.*"] [lemma="be"] -2 2))
'"either" and "or" within 6 tokens\tpreloaded/ententen21_tt31\t[word="either"][]{0,6}[word="or"]\n'
On line 85
(meet [word="either"] [word="or"] -5 5)
'"neither" and "nor" within 6 tokens\tpreloaded/ententen21_tt31\t[word="neither"][]{0,6}[word="nor"]\n'
On line 86
[lemma="neither"] [ ]{0,6} [lemma="nor"]
'"not only" and "but also" within 8 tokens\tpreloaded/ententen21_tt31\t[word=="not"][word="only"][]{0,8}[word=="but"][word=="also"]\n'
On line 87
[lemma="not"][lemma="only"] [ ]{0,8}[lemma="but"][lemma="also"]
'as ADJ as within same sentence\tpreloaded/ententen21_tt31\t[word="as"][tag="J.*"][word="as"] within <s/>\n'
On line 88
[lc="as"] [tag="JJ.*"] [lc="as"] within <s/>
'like a|an NOUN similes\tpreloaded/ententen21_tt31\t[lemma="like"][lemma="a|an"][tag="N.*"][word="similes"]\n'
On line 89
[word="like" | word="as"] [word="a" | word="an"] [tag="N.*"]
'such a|an NOUN\tpreloaded/ententen21_tt31\t[word="such"][word="a|an"][tag="N.*"]\n'
On line 90
[lemma="such"] [lemma="a"] [tag="N.*"]
'so ADJ that within 3 tokens\tpreloaded/ententen21_tt31\t[lemma="so"][tag="J.*"][]{0,3}[word="that"]\n'
On line 91
(meet [tag="J.*"] [word="that"] -3 3)
'too ADJ to VB\tpreloaded/ententen21_tt31\t[word="too"][tag="J.*"][word=="to"][tag="V[BHV]"]\n'
On line 92
[word="too"] [tag="J.*"] [word="to"] [tag="V.*"]
'enough NOUN\tpreloaded/ententen21_tt31\t[word="enough"][tag="N.*"]\n'
On line 93
[lemma="enough" & tag="N.*"]
'very ADJ patterns\tpreloaded/ententen21_tt31\t[word="very"][tag="J.*"]\n'
On line 94
[lemma="very"] [tag="JJ.*"]
'more/most ADJ\tpreloaded/ententen21_tt31\t[word="more|most"][tag="J.*"]\n'
On line 95
[tag="JJR"] | [tag="JJS"]
'more NOUN than NOUN\tpreloaded/ententen21_tt31\t[word="more"][tag="N.*"][word="than"][tag="N.*"]\n'
On line 96
[word="more"] [tag="N.*"] [word="than"] [tag="N.*"]
'the most ADJ\tpreloaded/ententen21_tt31\t[word="the"][word="most"][tag="J.*"]\n'
On line 97
[word="the"][word="most"][tag="J.*"]
'the least ADJ\tpreloaded/ententen21_tt31\t[word="the"][word="least"][tag="J.*"]\n'
On line 98
[tag="J.*"]
'as soon as\tpreloaded/ententen21_tt31\t[word="as"][word="soon"][word="as"]\n'
On line 99
[lemma="as"][lemma="soon"][lemma="as"]
'kind of NOUN\tpreloaded/ententen21_tt31\t[word=="kind"][word=="of"][tag="N.*"]\n'
On line 100
[lemma="kind"][lemma="of"][tag="N.*"]
'sort of NOUN\tpreloaded/ententen21_tt31\t[word=="sort"][word=="of"][tag="N.*"]\n'
On line 101
[lemma="sort"] [lemma="of"] [tag="N.*"]
'according to NOUN/PRON\tpreloaded/ententen21_tt31\t[lemma="according"][lemma="to"][tag="N.*|PP|WP|WPZ"]\n'
On line 102
[lemma="according"][lemma="to"][tag="N.*|PP|PPZ"]
'due to NOUN\tpreloaded/ententen21_tt31\t[lemma="due"][lemma="to"][tag="N.*"]\n'
On line 103
[lemma="due"] [lemma="to"] [tag="N.*"]
'because of NOUN\tpreloaded/ententen21_tt31\t[lemma="because"][lemma="of"][tag="N.*"]\n'
On line 104
[lc="because"] [lc="of"] [tag="N.*"]
'from NOUN to NOUN\tpreloaded/ententen21_tt31\t[word=="from"][tag="N.*"][word=="to"][tag="N.*"]\n'
On line 105
[tag="N.*"] [ ]{0,} [tag="N.*"]
'between NOUN and NOUN\tpreloaded/ententen21_tt31\t[word=="between"][tag="N.*"][word=="and"][tag="N.*"]\n'
On line 106
[tag="N.*"] [ ]{1,} [tag="N.*"]
'NOUN such as NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][word=="such"][word=="as"][tag="N.*"]\n'
On line 107
[tag="N.*"] [lemma="such"] [lemma="as"] [tag="N.*"]
'NOUN including NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="include"][tag="N.*"]\n'
On line 108
[tag="N.*"]
'NOUN especially NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="especially"][tag="N.*"]\n'
On line 109
[tag="N.*"] [word="especially"] [tag="N.*"]
'NOUN like NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="like"][tag="N.*"]\n'
On line 110
~"carrot-n"
'NOUN named NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="name"][tag="N.*"]\n'
On line 111
[tag="N.*"] [word="named"] [tag="N.*"]
'NOUN called NOUN\tpreloaded/ententen21_tt31\t[tag="N.*"][lemma="call"][tag="N.*"]\n'
On line 112
[tag="N.*"] [word="called"] [tag="N.*"]
'number of NOUN\tpreloaded/ententen21_tt31\t[lemma="number"][lemma="of"][tag="N.*"]\n'
On line 113
[tag="N.*"]
'amount of NOUN\tpreloaded/ententen21_tt31\t[lemma="amount"][lemma="of"][tag="N.*"]\n'
On line 114
[lemma="amount"] [lemma="of"] [tag="N.*"]
'pair of NOUNS\tpreloaded/ententen21_tt31\t[lemma="pair"][lemma="of"][tag="N.*"]\n'
On line 115
[tag="N.*"] [tag="N.*"]
'group of NOUNS\tpreloaded/ententen21_tt31\t[lemma="group"][lemma="of"][tag="N.*"]\n'
On line 116
[tag="N.*"]{2,}
'lack of NOUN\tpreloaded/ententen21_tt31\t[lemma="lack"][lemma="of"][tag="N.*"]\n'
On line 117
[tag != "N.*"]
'while ANY TOKEN\tpreloaded/ententen21_tt31\t[lemma="while"][]\n'
On line 118
[]
'if <token>\tpreloaded/ententen21_tt31\t[lemma="if"][]\n'
On line 119
[word="if"]
'unless [token]\tpreloaded/ententen21_tt31\t[lemma="unless"][]\n'
On line 120
[word!="unless"]
'since []\tpreloaded/ententen21_tt31\t[lemma="since"][]\n'
On line 121
[word="since"]
'during NOUN\tpreloaded/ententen21_tt31\t[lemma="during"][tag="N.*"]\n'
On line 122
[word="during"][tag="N.*"]
'within NOUN\tpreloaded/ententen21_tt31\t[lemma="within"][tag="N.*"]\n'
On line 123
[tag="N.*"] within <s/>
'outside NOUN\tpreloaded/ententen21_tt31\t[lemma="outside"][tag="N.*"]\n'
On line 124
[tag="N.*"] !within <s/>
'into NOUN\tpreloaded/ententen21_tt31\t[lemma="into"][tag="N.*"]\n'
On line 125
[lemma="into"] [tag="N.*"]
'out of NOUN\tpreloaded/ententen21_tt31\t[lemma="out"][lemma="of"][tag="N.*"]\n'
On line 126
[lemma="out"][lemma="of"][tag="N.*"]
'onto NOUN\tpreloaded/ententen21_tt31\t[lemma="onto"][tag="N.*"]\n'
On line 127
[word="onto"] [tag="N.*"]
'upon NOUN\tpreloaded/ententen21_tt31\t[lemma="upon"][tag="N.*"]\n'
On line 128
[lc="upon"] [tag="N.*"]
'towards NOUN\tpreloaded/ententen21_tt31\t[lemma="toward"][tag="N.*"]\n'
On line 129
[lemma="towards"][tag="N.*"]
'sentence without commas\tpreloaded/ententen21_tt31\t<s/> !containing [word==","]\n'
On line 130
<s/> !containing [word=","]
'sentence with colon\tpreloaded/ententen21_tt31\t<s/> containing [word==":"]\n'
On line 131
<s> [tag=":"] </s>
'sentence with semicolon\tpreloaded/ententen21_tt31\t<s/> containing [word==";"]\n'
On line 132
[word=";"] within <s/>
'sentence starting with capitalized word\tpreloaded/ententen21_tt31\t<s> [word="[[:upper:]].+"]\n'
On line 133
<s> [word="[A-Z].*"]
'sentence ending with proper noun\tpreloaded/ententen21_tt31\t[tag="NP|NPS"] </s>\n'
On line 134
<s> [tag="NP" | tag="NPS"] </s>
'sentence beginning with adverb then comma\tpreloaded/ententen21_tt31\t<s> [tag="RB.*"][word==","]\n'
On line 135
<s> [tag="RB"] [tag=","]
'paragraph containing a year\tpreloaded/ententen21_tt31\t<p/> containing [word="\\d{4}"]\n'
On line 136
<p/> containing [word="\d{4}"]
'paragraph without digits\tpreloaded/ententen21_tt31\t<p/> !containing [word=".*\\d.*"]\n'
On line 137
<p/> !containing [word=".*[0-9].*"]
'sentences inside docs genre=news\tpreloaded/ententen21_tt31\t<s/> within <doc genre=="news"/>\n'
On line 138
<doc genre="news"> <s/>
'sentences with no capitalized token\tpreloaded/ententen21_tt31\t<s/> !containing [word="[[:upper:]].*"]\n'
On line 139
<s/> !containing [word="[A-Z][A-Za-z]*"]
'quotation spans lacking nouns (<9 tokens) in one sentence\tpreloaded/ententen21_tt31\t([word="\\""][word!="\\""]{1,8}[word="\\""] !containing [tag="N.*"]) within <s/>\n'
On line 140
[tag="\""] [tag!="N.*"]{0,8} [tag="\""] within <s/>
'climate change in one sentence\tpreloaded/ententen21_tt31\t[lemma="climate"][lemma="change"] within <s/>\n'
On line 141
[lemma="climate"][lemma="change"]
'data-driven or data driven\tpreloaded/ententen21_tt31\t[word=="data-driven"] | ([word="data"][word="driven"])\n'
On line 142
[word="data-driven"] | ([word="data"][word="driven"])
'on the one hand ... on the other hand\tpreloaded/ententen21_tt31\t[word="on"][word="the"][word="one"][word="hand"][]{1,8}[word="on"][word="the"][word="other"][word="hand"]\n'
On line 143
[lemma="on"][lemma="the"][lemma="one"][lemma="hand"] [ ]{1,} [lemma="on"][lemma="the"][lemma="other"][lemma="hand"]
'repeated bigram A B ... A B within 6 tokens\tpreloaded/ententen21_tt31\t1:[] 2:[] []{0,6} 3:[] 4:[] & 1.word=3.word & 2.word=4.word\n'
On line 144
[word="*"] [word="*"] [ ]{0,4} [word="*"] [word="*"] & 1.word = 4.word & 2.word = 5.word
'two identical adjacent words\tpreloaded/ententen21_tt31\t1:[] 2:[] & 1.word = 2.word\n'
On line 145
1:[] 2:[] & 1.word = 2.word
'two adjacent tokens with same lemma\tpreloaded/ententen21_tt31\t1:[] 2:[] & 1.lemma = 2.lemma\n'
On line 146
1:[] 2:[] & 1.lemma = 2.lemma
'coordinated adjectives sharing lemma\tpreloaded/ententen21_tt31\t1:[tag="J.*"][tag="CC"] 2:[tag="J.*"] & 1.lemma = 2.lemma\n'
On line 147
1:[tag="JJ"] [word="and"] 3:[tag="JJ"] & 1.lemma = 3.lemma
'coordinated nouns with different lemmas\tpreloaded/ententen21_tt31\t1:[tag="N.*"][tag="CC"] 2:[tag="N.*"] & 1.lemma != 2.lemma\n'
On line 148
1:[tag="N.*"] 2:[tag="CC"] 3:[tag="N.*"] & 1.lemma != 3.lemma
'adjective not followed by noun\tpreloaded/ententen21_tt31\t[tag="J.*"][tag!="N.*"]\n'
On line 149
[tag="J.*"] [!tag="N.*"]?
'verb not preceded by determiner\tpreloaded/ententen21_tt31\t[tag!="DT"][tag="V.*"]\n'
On line 150
( <s> [tag="V.*"] ) | ( [tag!="DT"] [tag="V.*"] )
'present that is not a verb\tpreloaded/ententen21_tt31\t[word="present" & !tag="V.*"]\n'
On line 151
[lemma="present" & !tag="V.*"]
'object that is a noun not verb\tpreloaded/ententen21_tt31\t[lemma="object" & tag="N.*"]\n'
On line 152
[tag="N.*"]
'record as noun only\tpreloaded/ententen21_tt31\t[lemma="record" & tag="N.*"]\n'
On line 153
[lemma="record" & tag="N.*"]
'read as verb only\tpreloaded/ententen21_tt31\t[lemma="read" & tag="V.*"]\n'
On line 154
[lemma="read" & tag="V.*"]
'exact token "U.S."\tpreloaded/ententen21_tt31\t[word=="U.S."]\n'
On line 155
[word="U.S."]
'colour/color spelling variants\tpreloaded/ententen21_tt31\t[lemma="colou?r"]\n'
On line 156
[lc="colou?r"]
'centre/center variants\tpreloaded/ententen21_tt31\t[lemma="cent(er|re)"]\n'
On line 157
[lc="centre"] | [lc="center"]
'organisation/organization variants\tpreloaded/ententen21_tt31\t[word="organi[sz]ation"]\n'
On line 158
[lemma="organisation|organization"]
'analyse/analyze variants\tpreloaded/ententen21_tt31\t[lemma="analys(e|z)"]\n'
On line 159
[lc="analyse"] | [lc="analyze"]
'e-mail/email variants\tpreloaded/ententen21_tt31\t[word="e-?mail"]\n'
On line 160
[lc="email"] | [lc="e-mail"]
'cooperate/co-operate variants\tpreloaded/ententen21_tt31\t[lemma="co-?operate"]\n'
On line 161
[lc="cooperate"] | [lc="co-operate"]
're-creation/recreation variants\tpreloaded/ententen21_tt31\t[lemma="re-?creation"]\n'
On line 162
[lemma="recreation"]
'wellbeing/well-being variants\tpreloaded/ententen21_tt31\t[lemma="well-?being"]\n'
On line 163
[word="well-?being"]
'healthcare / health care variants\tpreloaded/ententen21_tt31\t[lemma="healthcare"] | [lemma="health"][lemma="care"]\n'
On line 164
([lemma="healthcare"]) | ([lemma="health"][lemma="care"])
'New York in any case\tpreloaded/ententen21_tt31\t[lc="new"][lc="york"]\n'
On line 165
[ lc = "new" ][ lc = "york" ]
'United States in any case\tpreloaded/ententen21_tt31\t[lc="united"][lc="states"]\n'
On line 166
[lc="united"][lc="states"]
'adjectives ending with -ious\tpreloaded/ententen21_tt31\t[lemma=".*ious" & tag="J.*"]\n'
On line 167
[tag="J.*" & lemma=".*ious"]
'verbs ending -ise/-ize\tpreloaded/ententen21_tt31\t[lemma=".*i[sz]e" & tag="V.*"]\n'
On line 168
[lemma=".*(?:ise|ize)$" & tag="V.*"]
'nouns ending -tion\tpreloaded/ententen21_tt31\t[lemma=".*tion" & tag="N.*"]\n'
On line 169
[tag="N.*" & lemma=".*tion"]
'agentive nouns ending -er/-or\tpreloaded/ententen21_tt31\t[lemma=".*(er|or)" & tag="N.*"]\n'
On line 170
[ (lemma=".*er$" | lemma=".*or$") & tag="N.*" ]
'words starting micro-\tpreloaded/ententen21_tt31\t[word="micro.*"]\n'
On line 171
[lc="micro-.*"]
'words ending -ology\tpreloaded/ententen21_tt31\t[word=".*ology"]\n'
On line 172
[lemma=".*ology"]
'Title Case tokens\tpreloaded/ententen21_tt31\t[word="[[:upper:]][[:lower:]]+"]\n'
On line 173
[word="^[A-Z][a-z]*$"]
'lowercase-only tokens\tpreloaded/ententen21_tt31\t[word="[[:lower:]]+"]\n'
On line 174
[word = "lc"]
'uppercase-only tokens\tpreloaded/ententen21_tt31\t[word="[[:upper:]]+"]\n'
On line 175
[word="^[A-Z]+$"]
'US or U.S.\tpreloaded/ententen21_tt31\t[word="US|U\\.S\\."]\n'
On line 176
[word="US"] | [word="U.S."]
'tokens not a dot (exact)\tpreloaded/ententen21_tt31\t[word!="."]\n'
On line 177
[word != "."]
'tokens lexicographically >= m\tpreloaded/ententen21_tt31\t[word>="m"]\n'
On line 178
[lc >= "m"]
'tokens lexicographically <= m\tpreloaded/ententen21_tt31\t[word<="m"]\n'
On line 179
[word <= "m"]
'verbs within documents topic=tech\tpreloaded/ententen21_tt31\t[tag="V.*"] within <doc topic=".*tech.*"/>\n'
On line 180
<doc topic="tech"> [tag="V.*"]
'sentences not containing digits\tpreloaded/ententen21_tt31\t<s/> !containing [word=".*\\d.*"]\n'
On line 181
<s/> !containing [word=".*[0-9].*"]
'nouns outside quotations\tpreloaded/ententen21_tt31\t[tag="N.*"] !within ([word="\\""][]{1,30}[word="\\""] within <s/>)\n'
On line 182
[tag="N.*"] !within <s/>
'paragraphs not containing proper nouns\tpreloaded/ententen21_tt31\t<p/> !containing [tag="NP.*"]\n'
On line 183
<p/> !containing [tag="NP|NPS|NPZ|NPSZ"]
'tokens between quotes not verbs\tpreloaded/ententen21_tt31\t([word="\\""][word!="\\""]{1,10}[word="\\""] !containing [tag="V.*"]) within <s/>\n'
On line 184
[word=="\""] [tag!="V.*"] [word=="\""]
'thesaurus: metals around corrosion +-4\tpreloaded/ententen21_tt31\t(meet ~"copper-n" [lemma="corrosion"] -4 4)\n'
On line 185
(meet ~"metal-n" [lemma="corrosion"] -4 4)
'thesaurus: vegetables after chop within 0–2\tpreloaded/ententen21_tt31\t[lemma="chop"][]{0,2} ~"carrot-n"\n'
On line 186
[lemma="chop"] []{0,2} ~"vegetable-n"
'thesaurus: 20 similar to city-n\tpreloaded/ententen21_tt31\t~20"city-n"\n'
On line 187
~20"city-n"
'invest followed by renewable-like within 3\tpreloaded/ententen21_tt31\t[lemma="invest"][]{0,3} ~"renewable-n"\n'
On line 188
[lemma="invest"] [ ]{0,2} [lc="renewable-like"]
'contact followed by doctor-like within 2\tpreloaded/ententen21_tt31\t[lemma="contact"][]{0,2} ~"doctor-n"\n'
On line 189
[lemma="contact"] [ ]{0,1} [lemma="doctor-like"]
'reduce near emission-like (+-5)\tpreloaded/ententen21_tt31\t(meet [lemma="reduce"] ~"emission-n" -5 5)\n'
On line 190
(meet [lemma="reduce"] [lemma="emission"] -5 5)
'noun within 2 tokens of adjective\tpreloaded/ententen21_tt31\t(meet [tag="N.*"] [tag="J.*"] -2 2)\n'
On line 191
(meet [tag="N.*"] [tag="J.*"] -2 2)
'verb within 1–4 tokens of noun to the right\tpreloaded/ententen21_tt31\t(meet [tag="V.*"] [tag="N.*"] 1 4)\n'
On line 192
[tag="N.*"] [ ]{1,4} [tag="V.*"]
'adjectives within 2–5 tokens of noun on left\tpreloaded/ententen21_tt31\t(meet [tag="J.*"] [tag="N.*"] -5 -2)\n'
On line 193
(meet [tag="J.*"] [tag="N.*"] 2 5)
'Nouns near was/were and adjectives near be\tpreloaded/ententen21_tt31\t(union (meet [tag="N.*"] [word=="was|were"] -2 2) (meet [tag="J.*"] [lemma="be"] -2 2))\n'
On line 194
(union (meet [tag="N.*"] [tag="VB.*"] -3 3) (meet [tag="J.*"] [tag="VB.*"] -3 3))
'Markers like (1) (2) ...\tpreloaded/ententen21_tt31\t[word=="("][word="\\d+"][word==")"]\n'
On line 195
[word="\(\d+\)"]
'dash-only tokens\tpreloaded/ententen21_tt31\t[word="-+"]\n'
On line 196
[word="-"]
'commas inside parentheses\tpreloaded/ententen21_tt31\t[word=="("][word=","][word==")"]\n'
On line 197
[tag="("][tag=","][tag=")"]
'proper noun + year\tpreloaded/ententen21_tt31\t[tag="NP"][word="\\d{4}"]\n'
On line 198
[tag="NP" | tag="NPS"] [tag="CD"]
'please + base verb\tpreloaded/ententen21_tt31\t[lemma="please"][tag="V[BHV]"]\n'
On line 199
[lemma="please"] [tag="VV"]
'so that sequences\tpreloaded/ententen21_tt31\t[word="so"][word="that"]\n'
On line 200
[lemma="so"][lemma="that"]
'in case sequences\tpreloaded/ententen21_tt31\t[word="in"][word="case"]\n'
On line 201
[lc="in"][lc="case"]
'as long as sequences\tpreloaded/ententen21_tt31\t[word="as"][word="long"][word="as"]\n'
On line 202
[word="as"][word="long"][word="as"]
'modal + not + base verb\tpreloaded/ententen21_tt31\t[word="can|could|may|might|must|shall|should|will|would"][lemma="not"][tag="V[BHV]"]\n'
On line 203
[tag="MD"] [word="not"] [tag="VV"]
'Word Sketch: modifiers of policy-n\tpreloaded/ententen21_tt31\t[ws("policy-n","modifiers of \\"%w\\"",".*")]\n'
On line 204
[ws("policy-n", "modifiers of \"%w\"", ".*")]
'Word Sketch: objects of approve-v\tpreloaded/ententen21_tt31\t[ws("approve-v",".*objects of \\"%w\\"",".*")]\n'
On line 205
[ws("approve-v", "objects of \"%w\"", ".*")]
'Word Sketch: subjects of increase-v\tpreloaded/ententen21_tt31\t[ws("increase-v",".*subjects of \\"%w\\"",".*")]\n'
On line 206
[ws("increase-v", "subjects of \"%w\"", ".*")]
'Word Sketch: decision-n as object of make-v\tpreloaded/ententen21_tt31\t[ws("decision-n",".*object.*","make-v")]\n'
On line 207
[ws("decision-n", "objects of \"%w\"", "make-v")]
'Word Sketch: test-n modified by blood-n\tpreloaded/ententen21_tt31\t[ws("test-n",".*modifiers of \\"%w\\"","blood-n")]\n'
On line 208
[ws("test-n", "modifiers of \"%w\"", "blood-n")]
'Word Sketch: any relation of climate-n mentioning change\tpreloaded/ententen21_tt31\t[ws("climate-n",".*","change.*")]\n'
On line 209
[ws("climate-n", ".*change.*", ".*")]
'Word Sketch: verbs with %w as subject\tpreloaded/ententen21_tt31\t[ws(".*","verbs with \\"%w\\" as subject",".*-v")]\n'
On line 210
[ws("word-n", "subjects of \"%w\"", ".*")]
'car in English where German segment has Auto\tpreloaded/europarl7_en\t[word="car"] within europarl7_de_1: [word="Auto"]\n'
On line 211
[lemma="car"] within europarl7_de: [lemma="Auto"]
'house in English where French segment has maison\tpreloaded/europarl7_en\t[word="house"] within europarl7_fr: [word="maison"]\n'
On line 212
[lemma="house"] within europarl7_fr: [word="maison"]
'Find a sentence consisting of as many words as is the meaning of life.\tpreloaded/ententen21_tt31\t<s> []{42} <s/>\n'
On line 213
<s> [word=".*"]{42} </s>
'Find a sentence having as many words as the meaning of life.\tpreloaded/ententen21_tt31\t<s> []{42,} <s/>\n'
On line 214
<s> [ ]{42} </s>
'Find a sentence having exactly as many words as the meaning of life.\tpreloaded/ententen21_tt31\t<s> []{42} <s/>\n'
On line 215
<s> & [word!=""]
'Find a sequence of as many tokens as is the meaning of life.\tpreloaded/ententen21_tt31\t[]{42}\n'
On line 216
[ ]{42}
'Find examples of subject and predicate. The subject should be a noun phrase.\tpreloaded/ententen21_tt31\t[ws(".*", "verbs with \\"%w\\" as subject", ".*-v")]\n'
On line 217
[ tag="DT" ]? [ tag="JJ.*" ]{0,} [ tag="N.*" ] [ tag="V.*" ]
'Find examples of subject and predicate.\tpreloaded/ententen21_tt31\t[ws(".*", "verbs with \\"%w\\" as subject", ".*-v")]\n'
On line 218
[tag="N.*"] [tag="V.*"] within <s/>
'Give me all the objects of a verb test.\tpreloaded/ententen21_tt31\t[ws("test-v", "objects of \\"%w\\"", ".*")]\n'
On line 219
[ws("test-v", "objects of \"%w\"", ".*")]
'Give me all the objects of the verb "test".\tpreloaded/ententen21_tt31\t[ws("test-v", "objects of \\"%w\\"", ".*")]\n'
On line 220
[ws("test-v", "objects of \"%w\"", ".*")]
'How do I find direct speech?\tpreloaded/ententen21_tt31\t[word="\\""] [word!="\\""]+ [word="\\""] within <s/>\n'
On line 221
<s/> containing [tag=="\""]
'How to find all noun phrases?\tpreloaded/ententen21_tt31\t[tag="J.*"]{0,5} [tag="N.*"]\n'
On line 222
<pheading>="<nphr/>" |  heading="nphr">
'I need to find all examples of direct speech.\tpreloaded/ententen21_tt31\t[word="\\""] [word!="\\""]+ [word="\\""] within <s/>\n'
On line 223
<quote/>
'I would like to filter out all simple prepositions in a corpus.\tpreloaded/ententen21_tt31\t<s/> !containing [tag="IN"]\n'
On line 224
[tag="IN"]
'Please give me all the objects of a verb test.\tpreloaded/ententen21_tt31\t[ws("test-v", "objects of \\"%w\\"", ".*")]\n'
On line 225
[ws("test-v", "objects of \"%w\"", ".*")]
'Hyphenated compounds with ≥3 parts (e.g., state-of-the-art)\tpreloaded/ententen21_tt31\t[word="[A-Za-z]+(-[A-Za-z]+){2,}"]\n'
On line 226
[word= "[a-zA-Z]+"] [word="-"] [word= "[a-zA-Z]+"] [word="-"] [word= "[a-zA-Z]+"] ( [word="-"] [word= "[a-zA-Z]+"] ){0,}
'Prefix re-, un-, de-, (optionally hyphenated)\tpreloaded/ententen21_tt31\t[word="(re|un|de)-?[a-z]+"]\n'
On line 227
[lemma_lc="re[a-z].*|un[a-z].*|de[a-z].*"]
'Prefix re-, un-, de- (must be hyphenated)\tpreloaded/ententen21_tt31\t[word="(re|un|de)-[a-z]+"]\n'
On line 228
[lemma="re-.*|un-.*|de-.*"]
'Case-insensitive match of "Internet"\tpreloaded/ententen21_tt31\t[lc="internet"]\n'
On line 229
[lc="internet"]
'The noun "policy".\tpreloaded/ententen21_tt31\t[lempos="policy-n"]\n'
On line 230
[lemma="policy" & tag="N.*"]
'Coordinating prepositions after "hand".\tpreloaded/ententen21_tt31\t[lemma="hand"][word="in|over|out"]\n'
On line 231
[word="hand"] [tag="CC"]
'Verb–particle constructions with short gaps\tpreloaded/ententen21_tt31\t[tag="V.*"] []{,2} [tag="RP"]\n'
On line 232
[tag="V.*"] [ ]{1,2} [tag="RP"]
'Examples of similes\tpreloaded/ententen21_tt31\t([lemma="like"] [word="the|a|an"]? [tag="N.*"]) | ([word="as"] [tag="J.*|RB.*"] [word="as"])\n'
On line 233
([lc="like" & tag="IN"] [tag="N.*"]) | ([lc="as" & tag="IN"] [tag="N.*"])
'Coordinated nouns captured as the whole sentence\tpreloaded/ententen21_tt31\t<s/> containing [tag="N.*"] [tag="CC"] [tag="DT"]? [tag="N.*"]\n'
On line 234
<s> [tag="N.*"] [tag="CC"] [tag="N.*"]
'Email domains like .edu or .org\tpreloaded/ententen21_tt31\t[word=".*@.*\\.(edu|org)"]\n'
On line 235
<doc tld="edu" | tld="org">
'Hex color codes\tpreloaded/ententen21_tt31\t[word="#([0-9A-Fa-f]{3}|[0-9A-Fa-f]{6})"]\n'
On line 236
[lc="#[0-9a-f]{6}"]
'IPv4 addresses\tpreloaded/ententen21_tt31\t[word="([12]?[0-9]?[0-9]\\.){3}[12]?[0-9]?[0-9]"]\n'
On line 237
[word="\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}"]
'Usernames beginning with @\tpreloaded/ententen21_tt31\t[word="@\\w+"]\n'
On line 238
[word="@.*"]
'Roman numerals I–X\tpreloaded/ententen21_tt31\t[word="(I|II|III|IV|V|VI|VII|VIII|IX|X)"]\n'
On line 239
[word="I{1,3}|IV|V|VI|VII|VIII|IX|X"]
'A month name followed by a year\tpreloaded/ententen21_tt31\t[lemma="january|february|march|april|may|june|july|august|september|october|november|december"][word="\\d{4}"]\n'
On line 240
[word="January|February|March|April|May|June|July|August|September|October|November|December" & tag="NP"] [tag="CD"]
'A weekday followed by a comma\tpreloaded/ententen21_tt31\t[lemma="monday|tuesday|wednesday|thursday|friday|saturday|sunday"][word==","]\n'
On line 241
[tag="NP"][tag=","]
'Any sentence that contains negation.\tpreloaded/ententen21_tt31\t<s/> containing [lemma="not"]\n'
On line 242
[word="not" | word=".*n't"] within <s/>
'Any token followed by a noun in a sentence.\tpreloaded/ententen21_tt31\t[][tag="N.*"] within <s/>\n'
On line 243
[ ] [tag="N.*"] within <s/>
'Any word followed by a noun in one sentence.\tpreloaded/ententen21_tt31\t[][tag="N.*"] within <s/>\n'
On line 244
[tag=".*"] [tag="N.*"] within <s/>
'Any word followed by a noun.\tpreloaded/ententen21_tt31\t[][tag="N.*"]\n'
On line 245
[ ] [tag="N.*"]
'Find adjectives followed by nouns.\tpreloaded/ententen21_tt31\t[tag="J.*"][tag="N.*"]\n'
On line 246
[tag="J.*"][tag="N.*"]
'Find all nouns with the verb to be at a distance of 3 tokens to the left or right and find all adjectives with the verb to be at a distance of 2 tokens to the left or right.\tpreloaded/ententen21_tt31\t(union (meet [tag="N.*"] [tag="VB.*"] -3 3) (meet [tag="J.*"] [tag="VB.*"] -2 2))\n'
On line 247
(union (meet [tag="N.*"] [tag="VB.*"] -3 3) (meet [tag="J.*"] [tag="VB.*"] -2 2))
'Find sentences that begin with the word An\tpreloaded/ententen21_tt31\t<s> [word="An"]\n'
On line 248
<s> [word="An"]
'Find sentences that begin with the word The\tpreloaded/ententen21_tt31\t<s> [word="The"]\n'
On line 249
<s> [word="The"]
'Find sentences that begin with the word "The"\tpreloaded/ententen21_tt31\t<s> [word="The"]\n'
On line 250
<s> [word="The"]
'Find the word however followed by a comma\tpreloaded/ententen21_tt31\t[word="however"] [word=","]\n'
On line 251
[word=="however"][word==","]
'Find the word however not followed by comma\tpreloaded/ententen21_tt31\t[word="however"] [word!="," ]\n'
On line 252
[word="however"] [tag!=","]
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 253
Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='localhost', port=8060): Read timed out. (read timeout=1200)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/run_model.py", line 39, in <module>
    translation = model.auto_call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 596, in auto_call
    cql = call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 573, in call
    model_response = call_einfra(prompt, api_key, use_grammar=True, corpname=params["corpname"])
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 216, in call_einfra
    resp = requests.post("http://localhost:8060/v1/chat/completions", headers=headers, json=payload, timeout=1200)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='localhost', port=8060): Read timed out. (read timeout=1200)
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 1
Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='localhost', port=8060): Read timed out. (read timeout=1200)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/run_model.py", line 39, in <module>
    translation = model.auto_call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 596, in auto_call
    cql = call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 573, in call
    model_response = call_einfra(prompt, api_key, use_grammar=True, corpname=params["corpname"])
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 216, in call_einfra
    resp = requests.post("http://localhost:8060/v1/chat/completions", headers=headers, json=payload, timeout=1200)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='localhost', port=8060): Read timed out. (read timeout=1200)
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 1
Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='localhost', port=8060): Read timed out. (read timeout=1200)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/run_model.py", line 39, in <module>
    translation = model.auto_call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 596, in auto_call
    cql = call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 573, in call
    model_response = call_einfra(prompt, api_key, use_grammar=True, corpname=params["corpname"])
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 216, in call_einfra
    resp = requests.post("http://localhost:8060/v1/chat/completions", headers=headers, json=payload, timeout=1200)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='localhost', port=8060): Read timed out. (read timeout=1200)
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 1
Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/run_model.py", line 39, in <module>
    translation = model.auto_call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 596, in auto_call
    cql = call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 573, in call
    model_response = call_einfra(prompt, api_key, use_grammar=True, corpname=params["corpname"])
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 216, in call_einfra
    resp = requests.post("http://localhost:8060/v1/chat/completions", headers=headers, json=payload, timeout=1200)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 1
Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/run_model.py", line 39, in <module>
    translation = model.auto_call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 596, in auto_call
    cql = call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 573, in call
    model_response = call_einfra(prompt, api_key, use_grammar=True, corpname=params["corpname"])
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 216, in call_einfra
    resp = requests.post("http://localhost:8060/v1/chat/completions", headers=headers, json=payload, timeout=1200)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 1
Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/urllib3/connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "/usr/lib64/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/usr/lib64/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/usr/lib64/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/run_model.py", line 39, in <module>
    translation = model.auto_call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 596, in auto_call
    cql = call(params)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 573, in call
    model_response = call_einfra(prompt, api_key, use_grammar=True, corpname=params["corpname"])
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/models/Qwen3_30B_A3B_Thinking_2507_IQ4_NL.py", line 216, in call_einfra
    resp = requests.post("http://localhost:8060/v1/chat/completions", headers=headers, json=payload, timeout=1200)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/xmikusek/diploma-thesis/evaluation/model_evaluation/Qwen3-30B-A3B-Thinking-2507-IQ4_NL_grammar/venv/lib64/python3.13/site-packages/requests/adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
'Find all four digits number starting with 19 following by word "a.d.".\tpreloaded/ententen21_tt31\t[word="19\\d{2}"][word="a"][word=="."][word="d"][word=="."]\n'
On line 1
[{'role': 'system', 'content': [{'type': 'text', 'text': 'Definition of Corpus Query Language (CQL)\n    The CQL is a query language used in Sketch Engine for searching grammatical and lexical patterns. CQL sets criteria for positions and tokens, such as tag, word, lemma, lempos, etc.\n    Basic syntax is [attribute="value"], for example:\n    To find the lemma teapot, use\n    CQL:\n    ```cql\n    [lemma="teapot"]\n    ```\n    Each token must be inside its own pair of square brackets. To search for the phrase refill the teapot, use\n    CQL:\n    ```cql\n    [lemma="refill"][lemma="the"][lemma="teapot"]\n    ```\n    More examples:\n    find examples of went -> CQL:\n    ```cql\n    [word="went"]\n    ```\n    find examples of all forms of go -> CQL:\n    ```cql\n    [lemma="go"]\n    ```\n    find examples of all words tagged with the tag NP -> CQL:\n    ```cql\n    [tag="NP"]\n    ```\n\n    Regular expressions can be used with values in CQL. A complete set of Regular expressions is supported, and complex criteria can be used, for example:\n    words starting with confus- -> CQL:\n    ```cql\n    [lemma="confus.*"]\n    ```\n    words ending with -ious -> CQL:\n    ```cql\n    [lemma=".*ious"]\n    ```\n    three-letter words starting b- and ending -g -> CQL:\n    ```cql\n    [lemma="b.g"]\n    ```\n    Be aware that when searching for any of the characters [][.*+{}?()|\\\\"$^] literally, they must be escaped using a backslash in any context where you may used regular expressions.\n\n    Square brackets [ ] stand for "any token". Curly brackets { } are used for repetition of the preceding token, for example:\n    find examples of ‘refill’ and ‘kettle’ with one word in between -> CQL:\n    ```cql\n    [lemma="refill"] [ ] [lemma="kettle"]\n    ```\n    examples of ‘have’ and ‘opinion’ with 2 to 4 words in between -> CQL:\n    ```cql\n    [lemma="have"] [ ]{2,4}[lemma="opinion"]\n    ```\n    find examples of "drink" and "water" with exactly two adjectives between them -> CQL:\n    ```cql\n    [lemma="drink"] [tag="J.*"]{2}[lemma="water"]\n    ```\n\n    A token can be made optional by placing a question mark ? after the square bracket. For example:\n    Find examples of ‘drive my car’ or ‘drive my own car’ -> CQL:\n    ```cql\n    [lemma="drive"] [lc="my"] [lc="own"]? [lemma="car"]\n    ```\n    alternative solution without using ? -> CQL:\n    ```cql\n    [lemma="drive"][lc="my"][lc="own"]{0,1} [lemma="car"]\n    ```\n\n    These comparison operators are supported:\n    equal =\n    less than or equal to <=\n    more than or equal to >=\n    not equal !=\n    not less than or equal to !<=\n    not more than or equal to !>=\n    equal (no regex) ==\n    not equal (no regex) !==\n    The alphabetical parts of the value are compared lexicographically (‘in the dictionary order’) and numerical parts numerically. This is useful with structure attributes, where >="AB2010CD" will include values such as "BB0000CD", "AB2011CD" or "AB2010CE". Example:\n    all one-letter words -> CQL:\n    ```cql\n    [word="."]\n    ```\n    all full stops -> CQL:\n    ```cql\n    [word=="."]\n    ```\n\n    One token can have more conditions. They must all appear inside the same pair of square brackets, and Boolean operators must be used between them.\n    & (ampersand) = AND\n    | (pipe) = OR\n    ! (exclamation mark) = NOT\n    For example:\n    Find all forms of the word ‘test’ which is a noun -> CQL:\n    ```cql\n    [ lemma="test" & tag="N.*" ]\n    ```\n    finds word ‘test’ which is NOT a verb -> CQL:\n    ```cql\n    [word="test" & tag!="V.*"]\n    ```\n    finds the word round tagged as a noun or verb -> CQL:\n    ```cql\n    [ word="round" & ( tag="N.*" | tag="V.*" ) ]\n    ```\n    finds word ‘test’ which is NOT a verb -> CQL:\n    ```cql\n    [word="test" & !tag="V.*"]\n    ```\n\n    | (pipe) = OR - means one token or another token, i.e., the token to the right or left of the pipe.\n    This use of the pipe (|) should only be limited to cases with no other solution because it consumes the search time. In most cases, it can be replaced by a pipe used inside the token, which is faster. See examples below.\n    "big dog" or "wolf" -> CQL:\n    ```cql\n    ([lemma="big"][lemma="dog"]) | [lemma="wolf"]\n    ```\n\n    Structures refer to sentences, paragraphs, documents, or any other parts or sections into which a corpus might be divided. Another way of saying this is that certain parts of a corpus can be labelled, e.g., direct speech might be labelled using structures to make it possible to limit the search to only direct speech. Structures may or may not have values. Values are used to categorize instances of the same structure.\n    Structures can be referred to in three ways:\n    The beginning: <s> <p> <doc> etc.\n    The end: </s> </p> </doc> etc.\n    The whole structure: <s/> <p/> <doc/> etc.\n    For example:\n    Find all documents written in informal style that start with the word Rebecca -> CQL:\n    ```cql\n    <doc style="informal">[lemma="Rebecca"]\n    ```\n    find all documents whose ID is 2011 and they start with a noun followed by a verb at a distance of up to 5 words -> CQL:\n    ```cql\n    <doc id="2011"> [tag="N.*"] []{0,5} [tag="V.*"]\n    ```\n    Written documents whose ID is 2011 and they start with a noun followed by a verb at a distance of up to 5 words -> CQL:\n    ```cql\n    <doc id="2011" & type="written"> [tag="N.*"] []{0,5} [tag="V.*"]\n    ```\n    find all verbs written in informal style -> CQL:\n    ```cql\n    [tag="V.*"]  within <doc style="informal" />\n    ```\n\n    The "containing" and "within" CQL operators are used to restrict the search only to a certain structure, e.g., to search inside:\n    Corpus structure, e.g., sentence, paragraph, document, etc.\n    Grammatical or lexical structure, e.g., noun phrase.\n\n    Use within to ensure the search result appears within the structure you want, in this case, within the same sentence, paragraph, document, or any other structure found in the corpus:\n    CQL:\n    ```cql\n    [word="dog"] []{0,5} [word="runs"] within < s/>\n    ```\n    The structure after "within" can be another CQL code defining a grammatical or lexical structure:\n    CQL:\n    ```cql\n    [tag="N.*"] within [tag="VB.*"] []{0,5} [tag="VB.*"]\n    ```\n    Multiple within operators can be nested if necessary:\n    CQL:\n    ```cql\n    [tag="N.*"] within ([tag="VB.*"] []{0,5} [tag="VB.*"] within < s/>)\n    ```\n    Use within to search a parallel corpus using this syntax:\n    within :\n    For example, with the English Europarl open, you can use this CQL to query the German Europarl. It will find all segments where the English corpus contains car and the aligned German segment contains Auto. In most cases, these will be segments where car was translated as Auto:\n    CQL:\n    ```cql\n    [word="car"] within europarl5_de: [word="Auto"]\n    ```\n\n    Use containing to find the whole structure and to display the whole structure as the result (KWIC).\n    This will find all paragraphs containing an acronym, i.e. a word consisting of 3 or more upper-case characters:\n    CQL:\n    ```cql\n    <p/> containing [word="[A-Z]{3,}"]\n    ```\n    This query searches for noun phrases (sequences of up to 5 adjectives followed by a noun) that contain the adjective international:\n    ```cql\n    [tag="J.*"]{1,5} [tag="N.*"] containing [word="international"]\n    ```\n\n    Use ! for negation:\n    !within = not within\n    !containing = not containing\n\n    This CQL will find all nouns that appear outside the <nphr> structure, i.e., outside noun phrases. The CQL will only work in corpora where the <nphr> structure exists:\n    CQL:\n    ```cql\n    [tag="N.*"]   !within   <nphr/>\n    ```\n    This CQL will find all sentences that do not contain any word starting with a capital letter:\n    CQL:\n    ```cql\n    <s/>   !containing   [word="[A-Z][A-Za-z]*"]\n    ```\n\n    Simultaneously searching the left and right context is only possible with meet and union operators. This is useful when a user wants to search for a token that is around or in the area of some other token.\n    Use meet to set the left and right context. This will find all nouns that have the verb to be 3 tokens to the left or 3 tokens to the right:\n    CQL:\n    ```cql\n    (meet [tag = "N.*"] [tag = "VB.*"] -3 3)\n    ```\n    Use the operator union to collect the results of two meet queries and display them in one concordance.\n    This CQL will, find all nouns with the verb to be at a distance of 3 tokens to the left or right, then find all adjectives with the verb to be at a distance of 2 tokens to the left or right, combine the nouns from the first query and adjectives from the second query and display them together in one concordance, the nouns and adjectives will be highlighted in the centre as KWIC:\n    CQL:\n    ```cql\n    (union (meet [tag="N.*"] [tag="VB.*"] -3 3) (meet [tag="A.*"] [tag="VB.*"] -2 2))\n    ```\n    This combines instances of nouns preceded by competent with adjectives followed by competence:\n    CQL:\n    ```cql\n    (union(meet [tag="N.*"] [lemma="competent"] -2 -1)(meet [tag="J.*"] [lemma="competence"]  1 2))\n    ```\n    Note that each meet and union has to be inside its own pair of brackets. Operators meet, and a union cannot be used with operators within and containing.\n\n    CQL also supports word sketch. Word sketches provide collocations for a word. The syntax is as follows:\n    CQL:\n    ```cql\n    [ws(headword, relation, collocation)]\n    ```\n    The relation is the name of the relation. You can often guess the name by using a regular expression like this:\n    CQL:\n    ```cql\n    [ws(headword, ".*subject.*", collocation)]\n    ```\n    For the exact name of the relation, the "%w" must be exchanged for \\"%w\\" as the quotes need to be backslashed in CQL. For example, the Word Sketch relation modifiers of "book" can be written as a CQL query:\n    CQL:\n    ```cql\n    [ws("book-n", "modifiers of \\"%w\\"", ".*")]\n    ```\n    Remember that Word Sketches are generated from lempos, so using a hyphen and the shortened PoS tag is necessary. For example, to generate a concordance with test (as a noun) being the object of conduct (as a verb), use this:\n    CQL:\n    ```cql\n    [ws("test-n",".*object.*","conduct-v")]\n    ```\n    In the resulting concordance, the headword is taken for a KWIC, and the collocations are used as a filter. It is possible to specify the headword by using the regular expression AND inside the square brackets. For example, to search for all relations of lempos "book-n" where the word appears in the plural form, you can use a CQL query:\n    CQL:\n    ```cql\n    [ws("book-n", ".*", ".*") & tag="NNS"]\n    ```\n    The prepositional phrases can be searched by the following syntax:\n    CQL:\n    ```cql\n    [ws("headword", "\\.\\.\\. [^ /]+ \\"%w\\"", ".*") | ws("headword", "\\"%w\\" [^ /]+ \\.\\.\\.", ".*")]\n    ```\n    In case only specific prepositions should be displayed, it is possible to insert them instead of [^ /]. This example will find concordance lines with the headword ‘test’ as a noun and prepositions of, in, or at:\n    CQL:\n    ```cql\n    [ws("test-n", "\\.\\.\\. (of|in|at) \\"%w\\"", ".*") | ws("test-n", "\\"%w\\" (of|in|at) \\.\\.\\.", ".*")]\n    ```\n    The Word Sketch CQL can be combined with other CQL markers. To generate a concordance where the headword test is modified by blood and followed or preceded by the lemma be, use this:\n    CQL:\n    ```cql\n    (meet [ws("test-n",".*modifiers of.*","blood-n")] [lemma="be"] -1 1)\n    ```\n\n    Thesaurus is also supported in CQL. Use the tilde ~ to generate a thesaurus (words with similar context, synonyms, antonyms) for the word and include the top N thesaurus items into the query. For example, to find the verb chop followed by vegetables, use this (or replace carrot with any other vegetable):\n    CQL:\n    ```cql\n    [lemma="chop"] []{0,3} ~"carrot-n"\n    ```\n    To set the number of thesaurus items manually, use:\n    CQL:\n    ```cql\n    ~15"carrot-n"\n    ```\n    CQL:\n    ```cql\n    [lemma="chop"] []{0,3} ~15"carrot-n"\n    ```\n    Thesaurus may be used with meet keyword, for example, to find all metals around the lemma corrosion:\n    CQL:\n    ```cql\n    (meet ~"metal-n" [lemma="corrosion"] -5 5)\n    ```\n\n    It is possible to add aditional constraints called global conditions.\n    You may use \'<number>:\' to specify a tag and then after whole CQL put & and write a global constraint. Only numbers may be used. For example:\n\n    Repetition of the same token:\n    CQL:\n    ```cql\n    1:[] 2:[] & 1.word = 2.word\n    ```\n    Repetition of the same token but different tag:\n    CQL:\n    ```cql\n    1:[] 2:[] & 1.word = 2.word & 1.tag != 2.tag\n    ```\n    Token with frequency higher than 2000\n    CQL:\n    ```cql\n    1:[] & f(1.word)>2000\n    ```\n\nYou are an expert assistant for Sketch Engine\'s Corpus Query Language (CQL).\nYour job is to read the conversation and translate the user\'s *latest* request into a single CQL query.\n\nImportant CQL reminders:\n- A query is a sequence of tokens, each inside square brackets: [ ... ].\n- Use attributes like word, lemma, tag, lc, lempos, structure attributes, etc.\n- Use regular expressions only when necessary.\n- Prefer lemma="..." when the user asks for \'all forms\' of a word.\n- Follow corpus-specific tags, annotations, structures and grammatical relations.\n\nCorpus description for corpus \'preloaded/ententen21_tt31\':\n### General Context\n- **Language**: English  \n- **Structures**:  \n  - Token-level: `word`, `tag`, `lempos`, `pos`, `lemma`, `lempos_lc` (lowercase lempos), `lemma_lc` (lowercase lemma), `lc` (lowercase word)  \n  - Document-level: `doc` with attributes: `url`, `title`, `wiki_categories`, `urldomain`, `website`, `crawl_date`, `modified_date`, `tld`, `wiki_translations`, `modified_month`, `modified_year`, `topic`, `tld_expl`, `domain_distance`, `genre`, `src`, `crawl_year`  \n  - Textual units: `s` (sentence), `p` (paragraph with attribute `heading`), `g` (unspecified)  \n- **Annotations**: Regex-based POS categories (e.g., `noun = "N.*"`).  \n- **Lempos Suffixes**: Concatenated to lemmas (e.g., noun: `-n`, verb: `-v`).  \n- **Word Sketch Relations**: Comprehensive set including subjects/objects/modifiers (e.g., `subjects of "%w"`, `verbs with "%w" as object`).  \n\n### How to Write CQL with Tagset  \n- **Strict Tag Format**: Tags must match exactly (case-sensitive) and be enclosed in double quotes.  \n  - Example: `[tag="NN"]` (singular noun), **not** `[tag="nn"]` or `[tag=NN]`.  \n- **Key Attributes**:  \n  - Token: `word`, `lemma`, `lc` (case-insensitive), `tag`, `lempos` (e.g., `[lempos="run-v"]`).  \n  - Document: Use `doc.attr` (e.g., `[doc.genre="news"]`).  \n  - Structures: Query within `s`, `p`, or `g` (e.g., `<s> [tag="VB"] </s>`).  \n- **Regex Support**: POS categories use regex in `tag` (e.g., `[tag="N.*"]` for all nouns).  \n\n### The Tagset  \nEach tag follows the format `[tag="TAG"]` (strictly enforced).  \n| **Tag**    | **Description**                                      | **Example**          |  \n|------------|------------------------------------------------------|----------------------|  \n| (empty)    | HTML/XML entities                                    | `<br>`               |  \n| " or "     | Quotation marks                                      | `"` `\'`              |  \n| (          | Left brackets                                        | `(` `[` `{`          |  \n| )          | Right brackets                                       | `)` `]` `}`          |  \n| ,          | Comma                                                | `,`                  |  \n| $          | Currency symbols                                     | `$` `£` `€`          |  \n| #          | Hash/Number sign                                     | `#`                  |  \n| :          | Punctuation: dashes, colon, semicolon, underscore    | `-` `:` `;` `_`      |  \n| CC         | Coordinating conjunction                             | `and`                |  \n| CD         | Cardinal number                                      | `1`, `one`           |  \n| CDZ        | Possessive numeral                                   | `one\'s`              |  \n| DT         | Determiner                                           | `the`                |  \n| EX         | Existential "there"                                  | `there` (in "there is") |  \n| FW         | Foreign word                                         | `d\'hoevre`           |  \n| IN         | Preposition/subordinating conjunction                | `in`, `of`           |  \n| IN/that    | Subordinator "that"                                  | `that` (as subordinator) |  \n| JJ         | Adjective                                            | `green`              |  \n| JJR        | Comparative adjective                                | `greener`            |  \n| JJS        | Superlative adjective                                | `greenest`           |  \n| LS         | List marker                                          | `1)`                 |  \n| MD         | Modal verb                                           | `could`, `will`      |  \n| NN         | Singular/mass noun                                   | `table`              |  \n| NNS        | Plural noun                                          | `tables`             |  \n| NNSZ       | Possessive plural noun                               | `people\'s`           |  \n| NNZ        | Possessive singular noun                             | `year\'s`             |  \n| NP         | Singular proper noun                                 | `John`               |  \n| NPS        | Plural proper noun                                   | `Vikings`            |  \n| NPSZ       | Possessive plural proper noun                        | `Boys\'`              |  \n| NPZ        | Possessive singular proper noun                      | `Britain\'s`          |  \n| PDT        | Predeterminer                                        | `both` (in "both the boys") |  \n| PP         | Personal pronoun                                     | `I`, `he`            |  \n| PPZ        | Possessive pronoun                                   | `my`, `his`          |  \n| RB         | Adverb                                               | `usually`            |  \n| RBR        | Comparative adverb                                   | `better`             |  \n| RBS        | Superlative adverb                                   | `best`               |  \n| RP         | Particle                                             | `up` (in "give up")  |  \n| SENT       | Sentence-ending punctuation                          | `.` `!` `?`          |  \n| SYM        | Symbol                                               | `/` `=` `*`          |  \n| TO         | Infinitive marker "to"                               | `to` (in "to go")    |  \n| UH         | Interjection                                         | `uhhuhh`             |  \n| VB         | Base form of "be"                                    | `be`                 |  \n| VBD        | Past tense of "be"                                   | `was`                |  \n| VBG        | Gerund/present participle of "be"                    | `being`              |  \n| VBN        | Past participle of "be"                              | `been`               |  \n| VBP        | Non-3rd person present of "be"                       | `am`, `are`          |  \n| VBZ        | 3rd person singular present of "be"                  | `is`                 |  \n| VH         | Base form of "have"                                  | `have`               |  \n| VHD        | Past tense of "have"                                 | `had`                |  \n| VHG        | Gerund/present participle of "have"                  | `having`             |  \n| VHN        | Past participle of "have"                            | `had`                |  \n| VHP        | Non-3rd person present of "have"                     | `have`               |  \n| VHZ        | 3rd person singular present of "have"                | `has`                |  \n| VV         | Base form of other verbs                             | `take`               |  \n| VVD        | Past tense of other verbs                            | `took`               |  \n| VVG        | Gerund/present participle of other verbs             | `taking`             |  \n| VVN        | Past participle of other verbs                       | `taken`              |  \n| VVP        | Non-3rd person present of other verbs                | `take`               |  \n| VVZ        | 3rd person singular present of other verbs           | `takes`              |  \n| WDT        | Wh-determiner                                        | `which`              |  \n| WP         | Wh-pronoun                                           | `who`, `what`        |  \n| WPZ        | Possessive wh-pronoun                                | `whose`              |  \n| WRB        | Wh-adverb                                            | `where`, `when`      |  \n| Z          | Possessive ending                                    | `\'s`                 |  \n\n### Key Quirks for CQL  \n1. **Lemmas**:  \n   - `a`/`an` both lemmatized as `a`.  \n   - Possessives (e.g., `\'s`) tokenized as part of the preceding word (e.g., `year\'s` → `year` + `Z`).  \n2. **Tokenization**:  \n   - Handles hashtags (`#`), emojis, and user handles.  \n   - `to` tagged as `IN` (preposition) or `TO` (infinitive marker).  \n3. **Word Sketches**: Use exact relation names (e.g., `"objects of \'%w\'"`).  \n4. **Case Sensitivity**:  \n   - Use `lc`, `lemma_lc`, or `lempos_lc` for case-insensitive queries.  \n   - `tag` is case-sensitive (e.g., `NN` ≠ `nn`).\n\nOutput format requirements (very important):\n1. Respond with EXACTLY one fenced code block.\n2. The fence must be in this format:\n```cql\n[your CQL query here]\n```\n3. Do output any text before the code block. Use this for reasoning.\n4. Do explain the query, comment on it, or paraphrase the user. Before the code block.\n5. Do not ask for clarification. Respond directly.\n'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'Find all four digits number starting with 19 following by word "a.d.".'}]}]
{"error":{"message":"Loading model","type":"unavailable_error","code":503}}
[word="19[0-9]{2}"][word="a\.d\.\\."]
'Find examples of noun phrases consisting of a minimum of three tokens.\tpreloaded/ententen21_tt31\t[tag="J.*|N.*"]{2,} [tag="N.*"]\n'
On line 2
[ ]{2,} [tag="N.*"]
'find patterns: "noun|adjective" or "adjective|noun\tpreloaded/ententen21_tt31\t([tag="N.*"][tag="J.*"]) | ([tag="J.*"][tag="N.*"])\n'
On line 3
([tag="N.*"][tag="J.*"])|([tag="J.*"][tag="N.*"])
'Phrase "no longer" or "no more"\tpreloaded/ententen21_tt31\t[lemma="no"][word="longer|more"]\n'
On line 4
([word="no"][word="longer"]) | ([word="no"][word="more"])
'Sentences ending with a question mark\tpreloaded/ententen21_tt31\t[word=="?"] </s>\n'
On line 5
<s> [word="?"] </s>
'Paragraphs that contain a 4-digit year.\tpreloaded/ententen21_tt31\t[word="[0-9]{4}"] within <p/>\n'
On line 6
<p/> containing [word="[0-9]{4}"]
'NP bigrams\tpreloaded/ententen21_tt31\t[tag="NP|NPS"]{2}\n'
On line 7
[tag="NP"] [tag="NP"]
'Nouns inside quotation spans\tpreloaded/ententen21_tt31\t[tag="N.*"] within [word="\\""] []{1,5} [word="\\""]\n'
On line 8
[word="\""] [tag="N.*"] [word="\""]
'Quatation marks not containing a noun in one sentence.\tpreloaded/ententen21_tt31\t([word="\\""][word!="\\""]{5,}[word="\\""] !containing [tag="N.*"]) within <s/>\n'
On line 9
[tag="\" or \""] within <s/> !containing [tag="N.*"]
'Negation near change verbs increase/decrease.\tpreloaded/ententen21_tt31\t(meet [lemma="increase" | lemma="decrease" & tag="V.*"] [lemma="not|never|none|neither"] -1 1)\n'
On line 10
(union (meet [lemma="increase"] [lemma="not"] -3 3) (meet [lemma="increase"] [lemma="no"] -3 3)  ) (meet [lemma="increase"] [lemma="never"] -3 3) (meet [lemma="decrease"] [lemma="not"] -3 3) (meet [lemma="decrease"] [lemma="no"] -3 3) (meet [lemma="decrease"] [lemma="never"] -3 3)
'Risk with a mitigate verb somewhere to its left (1–5 tokens away)\tpreloaded/ententen21_tt31\t(meet [lemma="risk"] [lemma="mitigate"] -5 -1)\n'
On line 11
(meet [lemma="risk"] [lemma="mitigate"] -5 -1)
'Coordinated adjectives where the lemmas are the same.\tpreloaded/ententen21_tt31\t1:[tag="J.*"] [tag="CC"] 2:[tag="J.*"] & 1.lemma = 2.lemma\n'
On line 12
1:[tag="J.*"] [word="and"] 3:[tag="J.*"] & 1.lemma = 3.lemma
'Immediate word repetitions\tpreloaded/ententen21_tt31\t1:[] 2:[] & 1.word = 2.word\n'
On line 13
1:[] 2:[] & 1.word = 2.word
'Any relation of policy-n where the collocation mentions climate.\tpreloaded/ententen21_tt31\t[ws("policy-n",".*",".*climate.*")]\n'
On line 14
[ws("policy-n", ".*climate.*", ".*")]
'Sentences where policy-n has a collocation reform-v in an “object-like” relation, and it’s preceded by governmental within 2 tokens.\tpreloaded/ententen21_tt31\t[word="governmental"] []{0,2} [ws("policy-n",".*object.*","reform-v")]\n'
On line 15
[lemma="governmental"] [ ]{0,1} [ws("policy-n", ".*object.*", "reform-v")] within <s/>
'"see" followed by a word similar to doctor-like profession.\tpreloaded/ententen21_tt31\t[lemma="see"] [tag="DT"]? ~10"doctor-n"\n'
On line 16
[lemma="see"] [word="~doctor-n"]
'Words similar to noun renewable with invest 0–3 to the left.\tpreloaded/ententen21_tt31\t[lemma="invest"] []{0,3} ~"renewable-n"\n'
On line 17
[lemma="invest"] []{0,3} ~"renewable-n"
'Thousands separators\tpreloaded/ententen21_tt31\t[word="[0-9]{1,3}(,[0-9]{3})+"]\n'
On line 18
[word=".*,"]
'capitalized words not sentence-initial\tpreloaded/ententen21_tt31\t[word="[A-Z].*"] within !<s> []\n'
On line 19
[ ] [word="[A-Z].*"] within <s/>
'Any token.\tpreloaded/ententen21_tt31\t[]\n'
On line 20
[ ]
'Find all verbs in the past tense.\tpreloaded/ententen21_tt31\t[tag="V.D"]\n'
On line 21
[tag="V.D"]
'Find any pronoun.\tpreloaded/ententen21_tt31\t[tag="PP.?|WP.?"]\n'
On line 22
[tag="PP" | tag="PPZ" | tag="WP" | tag="WPZ"]
'All-caps acronyms with 2+ letters\tpreloaded/ententen21_tt31\t[word="[A-Z]{2,}"]\n'
On line 23
[word="[A-Z]{2,}"]
'Ordinal numbers\tpreloaded/ententen21_tt31\t[word="\\d+(st|nd|rd|th)"]\n'
On line 24
[lemma=".*st|.*nd|.*rd|.*th"]
