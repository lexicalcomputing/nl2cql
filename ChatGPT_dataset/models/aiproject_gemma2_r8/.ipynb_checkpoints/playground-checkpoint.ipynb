{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43e4fa-dcda-4f36-8844-76fc9167d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl2cql - translation of natural language queries to Corpus Query Language\n",
    "# Copyright 2025 Ota MikuÅ¡ek\n",
    "# This program is licensed under GNU Lesser General Public License\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbaab85e-cefb-46a8-bf9e-0a7810ffc36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Any\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "import datasets\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0b86bf-0963-4944-87c5-51add03cac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "torch.cuda.manual_seed_all(21)\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c264eac-c63a-4b2b-bba6-ec98b5cf4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395ed951-d6c5-4e7c-8fd7-907f520e0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetNatural2CQL(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: Optional[str] = None) -> None:\n",
    "        self.sentence_freq = []\n",
    "        self.cql2nl = []\n",
    "        self.nl2cql = []\n",
    "        self.natural_language_rulebased = []\n",
    "        self.cql = []\n",
    "        self.natural_language = []\n",
    "        self.enabled_natural_language = []\n",
    "\n",
    "        if path is not None:\n",
    "            self.load_tsv(path)\n",
    "\n",
    "    def enable_cql(self, cqls):\n",
    "        self.enabled_natural_language = []\n",
    "        for cql in cqls:\n",
    "            for p in cql:\n",
    "                self.enabled_natural_language.append(p)\n",
    "\n",
    "    def dump_json(self, filepath: str) -> None:\n",
    "        with open(filepath, \"w\") as file:\n",
    "            for i in range(len(self)):\n",
    "                data = json.dumps(self[i])\n",
    "                file.write(data)\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "    def add_translation(self, freq: int, cql: str, natural_language_rulebased: str, natural_language: List[str]) -> None:\n",
    "        cql_index = len(self.sentence_freq)\n",
    "        self.sentence_freq.append(freq)\n",
    "        self.cql.append(cql)\n",
    "        self.natural_language_rulebased.append(natural_language_rulebased)\n",
    "        self.cql2nl.append([])\n",
    "\n",
    "        for sentence in natural_language:\n",
    "            self.nl2cql.append(cql_index)\n",
    "            self.cql2nl[-1].append(len(self.natural_language))\n",
    "            self.natural_language.append(sentence)\n",
    "\n",
    "    def load_tsv(self, path: str) -> None:\n",
    "        with open(path, \"r\") as file_data:\n",
    "            for line in file_data:\n",
    "                line = line.strip()\n",
    "                line = line.split(\"\\t\")\n",
    "                texts_json = json.loads(line[4])\n",
    "                texts_extracted = texts_json[\"data\"][0][\"content\"][0][\"text\"][\"value\"].split(\"\\n\")\n",
    "                self.add_translation(int(line[0]), line[2], line[3], texts_extracted)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.enabled_natural_language)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.nl2cql):\n",
    "            return {\"text\": self.natural_language[self.enabled_natural_language[idx]], \"cql\": self.cql[self.nl2cql[self.enabled_natural_language[idx]]]}\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3598ddd-dd1f-453c-b446-61508c5e1d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66e73033064466e9a30c31736b924e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c77a68-3ed0-41ce-afb2-f386a9e87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetNatural2CQL(\"expand_natural_texts_0004.res.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a0dec3-e66a-4321-96e5-62e696e8243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cqls = []\n",
    "with open(\"train_ids.json\", \"r\") as file:\n",
    "    train_cqls = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f64bb8f-5161-43bf-a857-deee2d1caeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.enable_cql(train_cqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21665ab7-73a0-464d-bb2f-a30a7c4d7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"'ain't', 'no', or 'not' followed by one or two unspecified tokens and resulting in 'nothing', 'nowhere', or 'nobody'.\",\n",
       " 'cql': '[word=\"ain\\'t|no|not\"][]{1,2}[word=\"nothing|nowhere|nobody\"]'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "dataset[len(dataset)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54448f57-a9bd-4970-bf54-9053953b6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dump_json(\"_tmp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c6b2762-15ce-4d2f-b681-e5a12fde4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d17e7968-01cf-4ef5-b0a7-11dc0d161227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3a397d093c41c59ec422e456f01406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_fancy = datasets.load_dataset(\"json\", data_files=\"_tmp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a4477d-8ae9-4be4-b755-a06b2dba00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_in(data):\n",
    "    full_input = \"\"\"Translate Natural Language into CQL Queries like:\n",
    "\n",
    "Word dog followed by lemma run and then followed by a noun. CQL:\n",
    "```\n",
    "[word=\"dog\"][lemma=\"run\"][pos=\"NN\"]\n",
    "```\n",
    "\n",
    "Lemma \"be\" optionaly followed by word \"not\". CQL:\n",
    "```\n",
    "[lemma=\"be\"][word=\"not\"]? \n",
    "```\n",
    "\n",
    "\"\"\" + data[\"text\"] + \" CQL:\\n```\\n\" + data[\"cql\"] + \"```<eos>\"\n",
    "    return tokenizer(full_input, truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12bc538-32cb-4695-be3b-bca1451e25a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37383981e0d4c37957c4cb94696f5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_fancy_tokenized = dataset_fancy.map(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd370962-f813-4edc-90f5-7f5eea1ed7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d333c210659149c98afaa8829dc1804a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/84984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_fancy_tokenized[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=2000,\n",
    "        save_steps=2000,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_dir='./logs',\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62db9f-2da6-4904-8977-b6971cf09e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to train Gemma2 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26211' max='424920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 26211/424920 14:50:44 < 225:50:35, 0.49 it/s, Epoch 0.62/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.340300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.326100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.299500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.298700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.297400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2620ab0-821a-40c9-b57d-2156d3a6b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"translate: Any word followed by lemma door as tag noun and then starting with open within sentence. ->\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4fc15-1e12-4e11-bd27-fb705f29c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"translate: Any word. ->\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbbf92-2b3d-4692-88d0-8994f6bac993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
